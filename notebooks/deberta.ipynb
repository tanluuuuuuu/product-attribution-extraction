{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f3ef1c-6fde-4129-b970-acac83ab9c7d",
   "metadata": {},
   "source": [
    "# Comet ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ffe1a43f-0bc9-480a-9b4a-9dd2d58d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ export COMET_API_KEY=\"ZNgNJ1VVgmaAbL0ga1t4mw3JI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "da014dee-fee0-4bea-8fc0-df9c5fc57b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !comet check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b71a53c6-eee5-48db-b81b-d40745ca82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f2734-2bcb-4ed9-a47c-ef27065eceeb",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d69a1ed5-07eb-4e64-b17f-53271809fdd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_checkpoint = \"microsoft/deberta-v3-large\"\n",
    "SEED = 42"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddd3f5-970f-4f8f-88ac-e2f25513cf88",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8a79ecd8-f512-4ec9-b382-b5fb5ad4d9e5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n",
      "/home/tanluuuuuuu/miniconda3/envs/one_for_all/lib/python3.8/site-packages/transformers/convert_slow_tokenizer.py:454: UserWarning: The sentencepiece tokenizer that you are converting to a fast tokenizer uses the byte fallback option which is not implemented in the fast tokenizers. In practice this means that the fast version of the tokenizer can produce unknown tokens whereas the sentencepiece version would have converted these unknown tokens into a sequence of byte tokens matching the original piece of text.\n",
      "  warnings.warn(\n",
      "Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74dd48-fd4d-426e-8d00-ea8c7934ca6e",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "34200f88-40a7-474f-a4f0-66b05fc7265b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MAT', 'I-MAT', 'B-NMAT', 'I-NMAT', 'B-DIMENSION', 'I-DIMENSION', 'B-WEIGHT', 'I-WEIGHT', 'B-TARGET_USER', 'I-TARGET_USER', 'B-PROPERTY', 'I-PROPERTY', 'B-COLOR', 'I-COLOR', 'B-SHAPE', 'I-SHAPE', 'B-SIZE', 'I-SIZE']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ner_tags = [\n",
    "\"MAT\",\n",
    "\"NMAT\",\n",
    "\"DIMENSION\",\n",
    "\"WEIGHT\",\n",
    "\"TARGET_USER\",\n",
    "\"PROPERTY\",\n",
    "\"COLOR\",\n",
    "\"SHAPE\",\n",
    "\"SIZE\",\n",
    "]\n",
    "\n",
    "processed_ner_tags = ['O']\n",
    "for tag in ner_tags:\n",
    "        processed_ner_tags.extend([f\"B-{tag}\", f\"I-{tag}\"])\n",
    "\n",
    "print(processed_ner_tags)\n",
    "print(len(processed_ner_tags))\n",
    "\n",
    "ner_tags_2_number = {t: i for (i, t) in enumerate(processed_ner_tags)}\n",
    "number_2_ner_tags = {t: i for (t, i) in enumerate(ner_tags_2_number)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "49c8e8ca-d9b3-4756-a8a7-b4090cd978be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4640 entries, 0 to 4639\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  4640 non-null   object\n",
      " 1   locs      4640 non-null   object\n",
      " 2   words     4640 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 108.9+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_excel_dataset = pd.read_excel(\"../data/data_from_09_10_2023/raw_data_restore_uppercase_11_1_2023.xlsx\")\n",
    "raw_excel_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "adbe29a1-5e60-4785-85c1-9ed1564f5ed6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def assign_ner_tags_deberta(example):\n",
    "    # print(example['sentence'])\n",
    "    token_input = tokenizer(example['sentence'])\n",
    "    example['tokens'] = tokenizer.convert_ids_to_tokens(\n",
    "        token_input['input_ids'])\n",
    "\n",
    "    # print(example['sentence'])\n",
    "    # print(example['tokens'])\n",
    "    # print(\"len: \", len(example['tokens']))\n",
    "\n",
    "    ner_tags = [0 for token in example['tokens']]\n",
    "    if str(type(example['locs'])) == \"<class 'list'>\":\n",
    "        locs = example['locs']\n",
    "    else:\n",
    "        locs = ast.literal_eval(example['locs'])\n",
    "\n",
    "    locs = [(int(loc[0]), int(loc[1]), loc[2]) for loc in locs]\n",
    "    locs = sorted(locs)\n",
    "    bg_id = 1\n",
    "    pre_loc = 0\n",
    "    text = example['sentence']\n",
    "    for loc in locs:\n",
    "        loc0 = int(loc[0])\n",
    "        loc1 = int(loc[1])\n",
    "\n",
    "        pre_text = text[pre_loc:loc0]\n",
    "        token_input = tokenizer(pre_text)\n",
    "        pre_token = tokenizer.convert_ids_to_tokens(\n",
    "            token_input['input_ids'])\n",
    "\n",
    "        # print(pre_text)\n",
    "        # print(pre_token)\n",
    "        # print(\"len: \", len(pre_token))\n",
    "\n",
    "        bg_id = bg_id + len(pre_token) - 2\n",
    "        pre_loc = loc1\n",
    "\n",
    "        # print(\"bg_id: \", bg_id)\n",
    "\n",
    "        word = example['sentence'][loc0: loc1]\n",
    "        token_input = tokenizer(word)\n",
    "        word_token = tokenizer.convert_ids_to_tokens(token_input['input_ids'])\n",
    "\n",
    "        label_number = ner_tags_2_number[f\"B-{loc[2]}\"]\n",
    "        ner_tags[bg_id] = label_number\n",
    "        bg_id += 1\n",
    "        for idx in range(bg_id, bg_id + len(word_token) - 3):\n",
    "            ner_tags[idx] = label_number + 1\n",
    "        bg_id = bg_id + len(word_token) - 3\n",
    "\n",
    "        # visualize_ner_tags(example['tokens'], ner_tags)\n",
    "\n",
    "    ner_tags[0] = -100\n",
    "    ner_tags[-1] = -100\n",
    "    return ner_tags\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "9a20d79e-5537-41da-94b7-66c49d583a11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['input_ids', 'attention_mask', 'labels'],\n",
       "    num_rows: 4640\n",
       "})"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, ClassLabel, Features, Value, Sequence\n",
    "\n",
    "list_input_ids = []\n",
    "list_attention_mask = []\n",
    "list_labels = []\n",
    "\n",
    "for index, row in raw_excel_dataset.iterrows():\n",
    "    try:\n",
    "        label = assign_ner_tags_deberta(row)\n",
    "        token_input = tokenizer(row['sentence'])\n",
    "        list_input_ids.append(token_input['input_ids'])\n",
    "        list_attention_mask.append(token_input['attention_mask'])\n",
    "        list_labels.append(label)\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        break\n",
    "        print(index)\n",
    "        print(row['sentence'])\n",
    "\n",
    "tokenized_datasets = pd.DataFrame()\n",
    "tokenized_datasets['input_ids'] = pd.Series(list_input_ids)\n",
    "tokenized_datasets['attention_mask'] = pd.Series(list_attention_mask)\n",
    "tokenized_datasets['labels'] = pd.Series(list_labels)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "train_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f27fabe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3712\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 928\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = train_dataset.train_test_split(test_size=0.2, shuffle=True, seed=7)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "7d614cde-7b24-4b68-8329-b2ee7fcdd0a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=4,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=4\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944dc69c-2a5a-412d-ad6e-42b0a20ac31d",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c74c316a-e2e6-435f-a596-92ebd61ad12f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9ed7d303-d16f-4018-9f69-6c3d286d0315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.39918747e-02 3.88201359e+00 8.30435028e+00 1.11280677e+01\n",
      " 1.04814367e+02 5.13319865e+00 8.70609850e-01 2.05736423e+01\n",
      " 1.26943751e+01 6.97505680e+00 2.54303710e+01 1.97762957e+00\n",
      " 1.67485708e+00 1.85113679e+01 1.58291085e+02 3.16582170e+01\n",
      " 4.30903509e+01 4.87815293e+01 2.67457350e+02]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def get_class_weight(train_dataset, num_class):\n",
    "    list_label = []\n",
    "    for label in train_dataset['labels']:\n",
    "        for cl in label:\n",
    "            if cl != -100:\n",
    "                list_label.append(cl)\n",
    "    class_weight = compute_class_weight(class_weight='balanced', classes=np.arange(num_class), y=list_label)\n",
    "    return class_weight\n",
    "\n",
    "class_weight = get_class_weight(tokenized_datasets[\"train\"], len(processed_ner_tags))\n",
    "print(class_weight)\n",
    "print(len(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b52a4-320b-46ed-8810-f20e01e03c34",
   "metadata": {},
   "source": [
    "## Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "5c08315b-93a9-4f4f-8c85-b13e93d0893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/wuharlem/simple-bert-w-hinge-loss\n",
    "\n",
    "from transformers import RobertaForTokenClassification, DebertaV2ForTokenClassification\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    " \n",
    "class CustomDebertaV2(DebertaV2ForTokenClassification):\n",
    "    def __init__(self, config, class_weight):\n",
    "        super().__init__(config)\n",
    "        self.class_weight = torch.tensor(class_weight, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "        \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "\n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            labels = labels.to(logits.device)\n",
    "            if self.class_weight is None:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=self.class_weight)\n",
    "                \n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "\n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e7ca6-c11d-495e-8913-d46a638ea008",
   "metadata": {},
   "source": [
    "## Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "52b2399f-a635-41f4-81ac-904b94e3d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-v3-large were not used when initializing CustomDebertaV2: ['lm_predictions.lm_head.bias', 'mask_predictions.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.bias', 'mask_predictions.classifier.weight', 'lm_predictions.lm_head.dense.weight', 'mask_predictions.dense.weight', 'mask_predictions.LayerNorm.bias', 'mask_predictions.LayerNorm.weight', 'mask_predictions.classifier.bias', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing CustomDebertaV2 from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomDebertaV2 from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomDebertaV2 were not initialized from the model checkpoint at microsoft/deberta-v3-large and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DebertaV2Config {\n",
      "  \"_name_or_path\": \"microsoft/deberta-v3-large\",\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 1024,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MAT\",\n",
      "    \"2\": \"I-MAT\",\n",
      "    \"3\": \"B-NMAT\",\n",
      "    \"4\": \"I-NMAT\",\n",
      "    \"5\": \"B-DIMENSION\",\n",
      "    \"6\": \"I-DIMENSION\",\n",
      "    \"7\": \"B-WEIGHT\",\n",
      "    \"8\": \"I-WEIGHT\",\n",
      "    \"9\": \"B-TARGET_USER\",\n",
      "    \"10\": \"I-TARGET_USER\",\n",
      "    \"11\": \"B-PROPERTY\",\n",
      "    \"12\": \"I-PROPERTY\",\n",
      "    \"13\": \"B-COLOR\",\n",
      "    \"14\": \"I-COLOR\",\n",
      "    \"15\": \"B-SHAPE\",\n",
      "    \"16\": \"I-SHAPE\",\n",
      "    \"17\": \"B-SIZE\",\n",
      "    \"18\": \"I-SIZE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 4096,\n",
      "  \"label2id\": {\n",
      "    \"B-COLOR\": 13,\n",
      "    \"B-DIMENSION\": 5,\n",
      "    \"B-MAT\": 1,\n",
      "    \"B-NMAT\": 3,\n",
      "    \"B-PROPERTY\": 11,\n",
      "    \"B-SHAPE\": 15,\n",
      "    \"B-SIZE\": 17,\n",
      "    \"B-TARGET_USER\": 9,\n",
      "    \"B-WEIGHT\": 7,\n",
      "    \"I-COLOR\": 14,\n",
      "    \"I-DIMENSION\": 6,\n",
      "    \"I-MAT\": 2,\n",
      "    \"I-NMAT\": 4,\n",
      "    \"I-PROPERTY\": 12,\n",
      "    \"I-SHAPE\": 16,\n",
      "    \"I-SIZE\": 18,\n",
      "    \"I-TARGET_USER\": 10,\n",
      "    \"I-WEIGHT\": 8,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-07,\n",
      "  \"max_position_embeddings\": 512,\n",
      "  \"max_relative_positions\": -1,\n",
      "  \"model_type\": \"deberta-v2\",\n",
      "  \"norm_rel_ebd\": \"layer_norm\",\n",
      "  \"num_attention_heads\": 16,\n",
      "  \"num_hidden_layers\": 24,\n",
      "  \"pad_token_id\": 0,\n",
      "  \"pooler_dropout\": 0,\n",
      "  \"pooler_hidden_act\": \"gelu\",\n",
      "  \"pooler_hidden_size\": 1024,\n",
      "  \"pos_att_type\": [\n",
      "    \"p2c\",\n",
      "    \"c2p\"\n",
      "  ],\n",
      "  \"position_biased_input\": false,\n",
      "  \"position_buckets\": 256,\n",
      "  \"relative_attention\": true,\n",
      "  \"share_att_key\": true,\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 0,\n",
      "  \"vocab_size\": 128100\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers.models.bert import modeling_bert\n",
    "from transformers import RobertaForTokenClassification, DebertaV2ForTokenClassification\n",
    "\n",
    "label_names = processed_ner_tags\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = CustomDebertaV2.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "3017f8bf-b894-4276-816d-34a3cb7e15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_train_epochs = 100\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "cd464490-cfce-4968-a24b-8985eabb42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e7c381da-3959-4a0b-8699-cdc5bcc6e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/luunvt/deberta-v3-large-ner-attribution-extraction/57573240eb1143bf89e203b8b076ab4c\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment, ExistingExperiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"ZNgNJ1VVgmaAbL0ga1t4mw3JI\",\n",
    "    project_name=\"deberta-v3-large-ner-attribution-extraction\",\n",
    "    workspace=\"luunvt\",\n",
    "    log_code=True\n",
    ")\n",
    "\n",
    "hyper_params = {\n",
    "    \"model\": model_checkpoint, \n",
    "    \"num_epochs\": num_train_epochs, \n",
    "    \"optimizer\": \"adamW\",\n",
    "    \"use_class_weight\": True,\n",
    "    \"num_train_sample\": len(tokenized_datasets[\"train\"]),\n",
    "    \"num_test_sample\": len(tokenized_datasets[\"test\"]),\n",
    "}\n",
    "experiment.log_parameters(hyper_params)\n",
    "experiment.add_tags([\"deberta-ner-classweight\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "8cc0fb11-dd79-422a-82f7-3f883314e99b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a DebertaV2TokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-11-02\n",
      "Time: 09:31:05\n",
      "epoch 0: {'precision': 0.6870229007633588, 'recall': 0.287636669470143, 'f1': 0.4055015413801281, 'accuracy': 0.835397634926862}\n",
      "Save best f1 model at epoch 0 with better f1 score 0.4055015413801281\n",
      "epoch 1: {'precision': 0.6842105263157895, 'recall': 0.32984698818516367, 'f1': 0.4451123889179299, 'accuracy': 0.864652805021577}\n",
      "Save best f1 model at epoch 1 with better f1 score 0.4451123889179299\n",
      "epoch 2: {'precision': 0.7175572519083969, 'recall': 0.37623762376237624, 'f1': 0.49364289662797123, 'accuracy': 0.8783836798744605}\n",
      "Save best f1 model at epoch 2 with better f1 score 0.49364289662797123\n",
      "epoch 3: {'precision': 0.7605464041783849, 'recall': 0.44932352243057205, 'f1': 0.5649059982094897, 'accuracy': 0.9004371462198061}\n",
      "Save best f1 model at epoch 3 with better f1 score 0.5649059982094897\n",
      "epoch 4: {'precision': 0.6998794696665327, 'recall': 0.39067055393586003, 'f1': 0.501439263097294, 'accuracy': 0.8881073810457882}\n",
      "Save model at epoch 5\n",
      "epoch 5: {'precision': 0.7581357975090398, 'recall': 0.4434782608695652, 'f1': 0.5596085409252669, 'accuracy': 0.8982233929271983}\n",
      "epoch 6: {'precision': 0.7621534752912816, 'recall': 0.39578552055080324, 'f1': 0.5210107113430377, 'accuracy': 0.8735638625791627}\n",
      "epoch 7: {'precision': 0.795098433105665, 'recall': 0.5093951093951093, 'f1': 0.6209601506118606, 'accuracy': 0.9179510172056269}\n",
      "Save best f1 model at epoch 7 with better f1 score 0.6209601506118606\n",
      "epoch 8: {'precision': 0.7894736842105263, 'recall': 0.5817051509769094, 'f1': 0.6698483040736323, 'accuracy': 0.9370621532253545}\n",
      "Save best f1 model at epoch 8 with better f1 score 0.6698483040736323\n",
      "epoch 9: {'precision': 0.7613499397348332, 'recall': 0.5263888888888889, 'f1': 0.6224338971916571, 'accuracy': 0.926105475536625}\n",
      "Save model at epoch 10\n",
      "epoch 10: {'precision': 0.7902772197669747, 'recall': 0.5728013977868375, 'f1': 0.6641904440317407, 'accuracy': 0.9348203777391694}\n",
      "epoch 11: {'precision': 0.5954198473282443, 'recall': 0.18298555377207062, 'f1': 0.27993955421231587, 'accuracy': 0.7681443703413103}\n",
      "epoch 12: {'precision': 0.7894736842105263, 'recall': 0.5544582392776524, 'f1': 0.6514172053704624, 'accuracy': 0.9289357170879337}\n",
      "epoch 13: {'precision': 0.7641623141824025, 'recall': 0.49402597402597404, 'f1': 0.6000946521533365, 'accuracy': 0.9202488370789665}\n",
      "epoch 14: {'precision': 0.7605464041783849, 'recall': 0.4786346396965866, 'f1': 0.5875232774674115, 'accuracy': 0.9119542677800818}\n",
      "Save model at epoch 15\n",
      "epoch 15: {'precision': 0.8015267175572519, 'recall': 0.5782608695652174, 'f1': 0.6718302744569794, 'accuracy': 0.9379028190326739}\n",
      "Save best f1 model at epoch 15 with better f1 score 0.6718302744569794\n",
      "epoch 16: {'precision': 0.8007231820008035, 'recall': 0.6502446982055465, 'f1': 0.7176809506661865, 'accuracy': 0.9488875189149807}\n",
      "Save best f1 model at epoch 16 with better f1 score 0.7176809506661865\n",
      "epoch 17: {'precision': 0.8015267175572519, 'recall': 0.621301775147929, 'f1': 0.7, 'accuracy': 0.9415457041977247}\n",
      "epoch 18: {'precision': 0.8055443953394937, 'recall': 0.6066565809379728, 'f1': 0.6920952709699689, 'accuracy': 0.9398363503895085}\n",
      "epoch 19: {'precision': 0.8047408597830454, 'recall': 0.6155500921942225, 'f1': 0.6975448371931047, 'accuracy': 0.9441237460068375}\n",
      "Save model at epoch 20\n",
      "epoch 20: {'precision': 0.8240257131378064, 'recall': 0.6142557651991615, 'f1': 0.703843514070007, 'accuracy': 0.9392478843243849}\n",
      "epoch 21: {'precision': 0.8111691442346324, 'recall': 0.6458733205374281, 'f1': 0.7191451469278718, 'accuracy': 0.946589699041641}\n",
      "Save best f1 model at epoch 21 with better f1 score 0.7191451469278718\n",
      "epoch 22: {'precision': 0.8111691442346324, 'recall': 0.6395312005068102, 'f1': 0.7151965993623804, 'accuracy': 0.94524463374993}\n",
      "epoch 23: {'precision': 0.7894736842105263, 'recall': 0.6246026700572155, 'f1': 0.6974267968056788, 'accuracy': 0.9449644118141568}\n",
      "epoch 24: {'precision': 0.8099638408999599, 'recall': 0.6857142857142857, 'f1': 0.7426782096150305, 'accuracy': 0.9531749145323096}\n",
      "Save best f1 model at epoch 24 with better f1 score 0.7426782096150305\n",
      "Save model at epoch 25\n",
      "epoch 25: {'precision': 0.8139815186822017, 'recall': 0.6195718654434251, 'f1': 0.7035943740232681, 'accuracy': 0.9373423751611276}\n",
      "epoch 26: {'precision': 0.8059461631177179, 'recall': 0.6931582584657913, 'f1': 0.7453093070778377, 'accuracy': 0.9542677800818248}\n",
      "Save best f1 model at epoch 26 with better f1 score 0.7453093070778377\n",
      "epoch 27: {'precision': 0.764965849738851, 'recall': 0.5517241379310345, 'f1': 0.641077441077441, 'accuracy': 0.9314016701227372}\n",
      "epoch 28: {'precision': 0.8099638408999599, 'recall': 0.6706586826347305, 'f1': 0.7337579617834395, 'accuracy': 0.9517738048534439}\n",
      "epoch 29: {'precision': 0.8047408597830454, 'recall': 0.684318414759139, 'f1': 0.7396602658788775, 'accuracy': 0.9540716247267836}\n",
      "Save model at epoch 30\n",
      "epoch 30: {'precision': 0.791080755323423, 'recall': 0.6370106761565836, 'f1': 0.7057347670250895, 'accuracy': 0.9404528386482094}\n",
      "epoch 31: {'precision': 0.810365608678184, 'recall': 0.6876917831571769, 'f1': 0.7440059018812246, 'accuracy': 0.9545480020175979}\n",
      "epoch 32: {'precision': 0.8051426275612696, 'recall': 0.6922279792746114, 'f1': 0.7444279346210995, 'accuracy': 0.9542117356946702}\n",
      "epoch 33: {'precision': 0.8075532342306148, 'recall': 0.6660039761431411, 'f1': 0.72998002542219, 'accuracy': 0.9492798296250631}\n",
      "epoch 34: {'precision': 0.7878666130976296, 'recall': 0.6929328621908127, 'f1': 0.7373566459860876, 'accuracy': 0.9540436025332063}\n",
      "Save model at epoch 35\n",
      "epoch 35: {'precision': 0.8043390920048212, 'recall': 0.6889194769442533, 'f1': 0.7421686746987951, 'accuracy': 0.9541837135010929}\n",
      "epoch 36: {'precision': 0.7922860586580956, 'recall': 0.6907180385288967, 'f1': 0.7380239520958084, 'accuracy': 0.9539595359524744}\n",
      "epoch 37: {'precision': 0.8095620731217357, 'recall': 0.6533722438391699, 'f1': 0.7231293737663735, 'accuracy': 0.9436753909096004}\n",
      "epoch 38: {'precision': 0.8115709120128566, 'recall': 0.6376262626262627, 'f1': 0.714159448470921, 'accuracy': 0.9444880345233425}\n",
      "epoch 39: {'precision': 0.8115709120128566, 'recall': 0.6803637588413607, 'f1': 0.7401978746793697, 'accuracy': 0.9532309589194642}\n",
      "Save model at epoch 40\n",
      "epoch 40: {'precision': 0.7991161108879068, 'recall': 0.6896671289875174, 'f1': 0.7403685092127303, 'accuracy': 0.9529787591772684}\n",
      "epoch 41: {'precision': 0.764965849738851, 'recall': 0.6193884189980482, 'f1': 0.6845227395290312, 'accuracy': 0.94148965981057}\n",
      "epoch 42: {'precision': 0.8079550020088389, 'recall': 0.6956070563818748, 'f1': 0.7475836431226766, 'accuracy': 0.9557529563414224}\n",
      "Save best f1 model at epoch 42 with better f1 score 0.7475836431226766\n",
      "epoch 43: {'precision': 0.8055443953394937, 'recall': 0.6866438356164384, 'f1': 0.7413569975965981, 'accuracy': 0.9521661155635263}\n",
      "epoch 44: {'precision': 0.7991161108879068, 'recall': 0.7028268551236749, 'f1': 0.7478849407783418, 'accuracy': 0.9549403127276803}\n",
      "Save best f1 model at epoch 44 with better f1 score 0.7478849407783418\n",
      "Save model at epoch 45\n",
      "epoch 45: {'precision': 0.8079550020088389, 'recall': 0.6746058369674606, 'f1': 0.7352833638025594, 'accuracy': 0.9507369836910834}\n",
      "epoch 46: {'precision': 0.8031337886701486, 'recall': 0.7088652482269504, 'f1': 0.7530608400828781, 'accuracy': 0.9548282239533711}\n",
      "Save best f1 model at epoch 46 with better f1 score 0.7530608400828781\n",
      "epoch 47: {'precision': 0.8035355564483728, 'recall': 0.7135212272565109, 'f1': 0.7558578987150415, 'accuracy': 0.9557809785349998}\n",
      "Save best f1 model at epoch 47 with better f1 score 0.7558578987150415\n",
      "epoch 48: {'precision': 0.7746082764162314, 'recall': 0.6772040744643484, 'f1': 0.7226386806596701, 'accuracy': 0.9492798296250631}\n",
      "epoch 49: {'precision': 0.8043390920048212, 'recall': 0.6779546224178801, 'f1': 0.7357589121646454, 'accuracy': 0.9492237852379084}\n",
      "Save model at epoch 50\n",
      "epoch 50: {'precision': 0.8035355564483728, 'recall': 0.6828269033799932, 'f1': 0.7382798080472499, 'accuracy': 0.9510732500140111}\n",
      "epoch 51: {'precision': 0.8135797509039775, 'recall': 0.6880733944954128, 'f1': 0.745581737849779, 'accuracy': 0.9521661155635263}\n",
      "epoch 52: {'precision': 0.8083567697870631, 'recall': 0.7034965034965035, 'f1': 0.7522901476911572, 'accuracy': 0.9541276691139382}\n",
      "epoch 53: {'precision': 0.8095620731217357, 'recall': 0.6941095418532552, 'f1': 0.7474035608308606, 'accuracy': 0.9532309589194642}\n",
      "epoch 54: {'precision': 0.8079550020088389, 'recall': 0.7053665380568221, 'f1': 0.7531835205992509, 'accuracy': 0.953847447178165}\n",
      "Save model at epoch 55\n",
      "epoch 55: {'precision': 0.8184009642426677, 'recall': 0.6863207547169812, 'f1': 0.7465640461792195, 'accuracy': 0.9511853387883203}\n",
      "epoch 56: {'precision': 0.8147850542386501, 'recall': 0.6638297872340425, 'f1': 0.7316017316017316, 'accuracy': 0.9500364288516505}\n",
      "epoch 57: {'precision': 0.8003214142225793, 'recall': 0.7222625090645395, 'f1': 0.7592910234419669, 'accuracy': 0.9564815333744325}\n",
      "Save best f1 model at epoch 57 with better f1 score 0.7592910234419669\n",
      "epoch 58: {'precision': 0.812374447569305, 'recall': 0.7157522123893806, 'f1': 0.7610086563793752, 'accuracy': 0.9558370229221543}\n",
      "Save best f1 model at epoch 58 with better f1 score 0.7610086563793752\n",
      "epoch 59: {'precision': 0.769385295299317, 'recall': 0.6385461820606869, 'f1': 0.6978862973760933, 'accuracy': 0.9426665919408171}\n",
      "Save model at epoch 60\n",
      "epoch 60: {'precision': 0.8071514664523906, 'recall': 0.7182695745441544, 'f1': 0.7601210745365115, 'accuracy': 0.9549403127276803}\n",
      "epoch 61: {'precision': 0.8188027320208919, 'recall': 0.7037292817679558, 'f1': 0.7569173630454966, 'accuracy': 0.9546881129854845}\n",
      "epoch 62: {'precision': 0.8083567697870631, 'recall': 0.7332361516034985, 'f1': 0.7689661761895662, 'accuracy': 0.9583029759569579}\n",
      "Save best f1 model at epoch 62 with better f1 score 0.7689661761895662\n",
      "epoch 63: {'precision': 0.8135797509039775, 'recall': 0.7085374387683695, 'f1': 0.7574340751823454, 'accuracy': 0.9548842683405256}\n",
      "epoch 64: {'precision': 0.816793893129771, 'recall': 0.7214336408800568, 'f1': 0.7661579046542303, 'accuracy': 0.9571540660202881}\n",
      "Save model at epoch 65\n",
      "epoch 65: {'precision': 0.7987143431096826, 'recall': 0.7319587628865979, 'f1': 0.76388088376561, 'accuracy': 0.9564815333744325}\n",
      "epoch 66: {'precision': 0.8007231820008035, 'recall': 0.7386953298739807, 'f1': 0.7684596105648736, 'accuracy': 0.9585551756991537}\n",
      "epoch 67: {'precision': 0.8083567697870631, 'recall': 0.7424354243542436, 'f1': 0.7739949990382767, 'accuracy': 0.9583590203441126}\n",
      "Save best f1 model at epoch 67 with better f1 score 0.7739949990382767\n",
      "epoch 68: {'precision': 0.8071514664523906, 'recall': 0.728955007256894, 'f1': 0.7660629170638703, 'accuracy': 0.9578265986661436}\n",
      "epoch 69: {'precision': 0.8308557653676175, 'recall': 0.6322225619076735, 'f1': 0.7180555555555556, 'accuracy': 0.9431149470380541}\n",
      "Save model at epoch 70\n",
      "epoch 70: {'precision': 0.8071514664523906, 'recall': 0.723963963963964, 'f1': 0.7632978723404256, 'accuracy': 0.9566496665358964}\n",
      "epoch 71: {'precision': 0.8043390920048212, 'recall': 0.7379284924437891, 'f1': 0.7697039600153787, 'accuracy': 0.9577425320854116}\n",
      "epoch 72: {'precision': 0.8099638408999599, 'recall': 0.717948717948718, 'f1': 0.761185576741552, 'accuracy': 0.956341422406546}\n",
      "epoch 73: {'precision': 0.8091603053435115, 'recall': 0.7262892174540209, 'f1': 0.765488407449639, 'accuracy': 0.9567337331166283}\n",
      "epoch 74: {'precision': 0.8063479308959421, 'recall': 0.693024861878453, 'f1': 0.7454038997214485, 'accuracy': 0.95348315866166}\n",
      "Save model at epoch 75\n",
      "epoch 75: {'precision': 0.8027320208919244, 'recall': 0.721820809248555, 'f1': 0.7601293513410691, 'accuracy': 0.9576584655046797}\n",
      "epoch 76: {'precision': 0.8051426275612696, 'recall': 0.7295231161266836, 'f1': 0.7654698242933536, 'accuracy': 0.9588634198285042}\n",
      "epoch 77: {'precision': 0.8031337886701486, 'recall': 0.7381831610044313, 'f1': 0.7692899749855685, 'accuracy': 0.9595919968615143}\n",
      "epoch 78: {'precision': 0.8079550020088389, 'recall': 0.7371700879765396, 'f1': 0.7709411539198774, 'accuracy': 0.9587793532477722}\n",
      "epoch 79: {'precision': 0.8007231820008035, 'recall': 0.7337997054491899, 'f1': 0.7658021133525456, 'accuracy': 0.958583197892731}\n",
      "Save model at epoch 80\n",
      "epoch 80: {'precision': 0.7983125753314584, 'recall': 0.7469924812030075, 'f1': 0.7718003495824433, 'accuracy': 0.9599843075715967}\n",
      "epoch 81: {'precision': 0.8031337886701486, 'recall': 0.7445065176908753, 'f1': 0.7727097023579435, 'accuracy': 0.9596760634422462}\n",
      "epoch 82: {'precision': 0.8111691442346324, 'recall': 0.7136797454931071, 'f1': 0.7593080105302745, 'accuracy': 0.9546600907919072}\n",
      "epoch 83: {'precision': 0.8119726797910808, 'recall': 0.702223766504517, 'f1': 0.7531209241662008, 'accuracy': 0.9547441573726392}\n",
      "epoch 84: {'precision': 0.8087585375652873, 'recall': 0.732532751091703, 'f1': 0.7687607408821844, 'accuracy': 0.957854620859721}\n",
      "Save model at epoch 85\n",
      "epoch 85: {'precision': 0.8071514664523906, 'recall': 0.7316096139839767, 'f1': 0.7675262655205348, 'accuracy': 0.9578265986661436}\n",
      "epoch 86: {'precision': 0.8083567697870631, 'recall': 0.736996336996337, 'f1': 0.7710289327457367, 'accuracy': 0.9585271535055764}\n",
      "epoch 87: {'precision': 0.8055443953394937, 'recall': 0.736320235034888, 'f1': 0.7693783576362241, 'accuracy': 0.9583590203441126}\n",
      "epoch 88: {'precision': 0.8059461631177179, 'recall': 0.7310495626822158, 'f1': 0.7666730364991401, 'accuracy': 0.9578826430532982}\n",
      "epoch 89: {'precision': 0.8119726797910808, 'recall': 0.7181947405828003, 'f1': 0.7622100697718273, 'accuracy': 0.9555007565992266}\n",
      "Save model at epoch 90\n",
      "epoch 90: {'precision': 0.8067496986741663, 'recall': 0.7325793506019701, 'f1': 0.7678776290630975, 'accuracy': 0.9578826430532982}\n",
      "epoch 91: {'precision': 0.8087585375652873, 'recall': 0.7346715328467154, 'f1': 0.7699368904188181, 'accuracy': 0.9581068206019168}\n",
      "epoch 92: {'precision': 0.8043390920048212, 'recall': 0.7420311341734618, 'f1': 0.7719298245614035, 'accuracy': 0.9592557305385866}\n",
      "epoch 93: {'precision': 0.8067496986741663, 'recall': 0.7385068039720486, 'f1': 0.771121351766513, 'accuracy': 0.9583870425376898}\n",
      "epoch 94: {'precision': 0.8047408597830454, 'recall': 0.742677048572488, 'f1': 0.7724643270343233, 'accuracy': 0.959031552989968}\n",
      "Save model at epoch 95\n",
      "epoch 95: {'precision': 0.7987143431096826, 'recall': 0.7493403693931399, 'f1': 0.7732399844418514, 'accuracy': 0.9597040856358235}\n",
      "epoch 96: {'precision': 0.8027320208919244, 'recall': 0.7438570364854803, 'f1': 0.7721739130434784, 'accuracy': 0.9592277083450093}\n",
      "epoch 97: {'precision': 0.8027320208919244, 'recall': 0.7449664429530202, 'f1': 0.7727712241345968, 'accuracy': 0.9591156195707}\n",
      "epoch 98: {'precision': 0.8047408597830454, 'recall': 0.7437801708132195, 'f1': 0.7730605943651101, 'accuracy': 0.9591716639578546}\n",
      "epoch 99: {'precision': 0.8047408597830454, 'recall': 0.7451636904761905, 'f1': 0.7738072242611551, 'accuracy': 0.9592277083450093}\n",
      "Save model at epoch 100\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/luunvt/deberta-v3-large-ner-attribution-extraction/57573240eb1143bf89e203b8b076ab4c\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     loss [9280]          : (4.944258307659766e-06, 4.1543660163879395)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_accuracy [100]  : (0.7681443703413103, 0.9599843075715967)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_f1 [100]        : (0.27993955421231587, 0.7739949990382767)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_precision [100] : (0.5954198473282443, 0.8308557653676175)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_recall [100]    : (0.18298555377207062, 0.7493403693931399)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model            : microsoft/deberta-v3-large\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_epochs       : 100\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_test_sample  : 928\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_sample : 3712\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer        : adamW\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_class_weight : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (754.27 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[36m─────────────────────────────────────────────── \u001b[0m\u001b[1;36mNew Comet feature!\u001b[0m\u001b[36m ───────────────────────────────────────────────\u001b[0m\n",
      "Log your models to better track, deploy, share, and reproduce your work using: 'comet_ml.integration.pytorch.log_model'.\n",
      "Learn more at: https://comet.com/docs/v2/pytorch_log_model\n",
      "\n",
      "Hide this message by setting environment variable \"COMET_DISABLE_ANNOUNCEMENT=1\" \n",
      "\u001b[36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Please wait for metadata to finish uploading (timeout is 3600 seconds)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Uploading 1 metrics, params and output messages\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "\n",
    "date_time = datetime.now()\n",
    "format_date = date_time.strftime('%Y-%m-%d')\n",
    "format_time = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "print(f\"Date: {format_date}\")\n",
    "print(f\"Time: {format_time}\")\n",
    "\n",
    "output_dir = f\"../models/model_from_{format_date}/deberta-v3-large-_{format_time}\"\n",
    "\n",
    "best_f1_score = 0\n",
    "    \n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "    with experiment.test():\n",
    "        # Evaluation\n",
    "        model.eval()\n",
    "        for batch in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "\n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "\n",
    "            # Necessary to pad predictions and labels for being gathered\n",
    "            predictions = accelerator.pad_across_processes(\n",
    "                predictions, dim=1, pad_index=-100)\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                labels, dim=1, pad_index=-100)\n",
    "\n",
    "            predictions_gathered = accelerator.gather(predictions)\n",
    "            labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "            true_predictions, true_labels = postprocess(\n",
    "                predictions_gathered, labels_gathered)\n",
    "            metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "        results = metric.compute()\n",
    "        print(\n",
    "            f\"epoch {epoch}:\",\n",
    "            {\n",
    "                key: results[f\"overall_{key}\"]\n",
    "                for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "            },\n",
    "        )\n",
    "\n",
    "        if experiment:\n",
    "            experiment.set_epoch(epoch)\n",
    "            experiment.log_metric(\"precision\", results[\"overall_precision\"])\n",
    "            experiment.log_metric(\"recall\", results[\"overall_recall\"])\n",
    "            experiment.log_metric(\"f1\", results[\"overall_f1\"])\n",
    "            experiment.log_metric(\"accuracy\", results[\"overall_accuracy\"])\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    unwrapped_model.save_pretrained(output_dir, save_function=accelerator.save)\n",
    "    if accelerator.is_main_process and results[f\"overall_f1\"] > best_f1_score:\n",
    "        output_ckpt = os.path.join(output_dir, f'best_f1')\n",
    "        best_f1_score = results[f\"overall_f1\"]\n",
    "        print(\n",
    "            f\"Save best f1 model at epoch {epoch} with better f1 score {best_f1_score}\")\n",
    "        tokenizer.save_pretrained(output_dir)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            output_ckpt, save_function=accelerator.save)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        output_ckpt = os.path.join(output_dir, f'epoch_{epoch + 1}')\n",
    "        print(f\"Save model at epoch {epoch + 1}\")\n",
    "        tokenizer.save_pretrained(output_ckpt)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            output_ckpt, save_function=accelerator.save)\n",
    "experiment.end()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one_for_all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0e8147b5-9098-411a-ba9c-d23d49751e6b",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8d565e98-c04f-43aa-aa17-86cd05bc4c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "# https://www.kaggle.com/code/wuharlem/simple-bert-w-hinge-loss\n",
    "\n",
    "from transformers import DebertaV2ForTokenClassification, DebertaV2Model\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    " \n",
    "class CustomDeberta(DebertaV2ForTokenClassification):\n",
    "    def __init__(self, config, class_weight=None):\n",
    "        super().__init__(config)\n",
    "        self.class_weight = torch.tensor(class_weight, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "      \n",
    "    def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.Tensor] = None,\n",
    "        attention_mask: Optional[torch.Tensor] = None,\n",
    "        token_type_ids: Optional[torch.Tensor] = None,\n",
    "        position_ids: Optional[torch.Tensor] = None,\n",
    "        inputs_embeds: Optional[torch.Tensor] = None,\n",
    "        labels: Optional[torch.Tensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple, TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "    \n",
    "        outputs = self.deberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "    \n",
    "        sequence_output = outputs[0]\n",
    "    \n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "    \n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            labels = labels.to(logits.device)\n",
    "            if self.class_weight is None:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=self.class_weight)\n",
    "                \n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "    \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[1:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "    \n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss, logits=logits, hidden_states=outputs.hidden_states, attentions=outputs.attentions\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "766b7c4b-ce68-4aa4-a223-667867b26a79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "# https://huggingface.co/docs/transformers/tasks/token_classification\n",
    "model_checkpoint = \"microsoft/deberta-v2-xlarge\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c075b03d-a1ad-4fbc-bee2-47736c84a006",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CUDA:  True\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "print(\"CUDA: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4a28e3c-671b-4218-a3c1-f055a5f25318",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "146c99a5-cc6f-4b62-a2ca-08c877823827",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MAT', 'I-MAT', 'B-NMAT', 'I-NMAT', 'B-DIMENSION', 'I-DIMENSION', 'B-WEIGHT', 'I-WEIGHT', 'B-TARGET_USER', 'I-TARGET_USER', 'B-PROPERTY', 'I-PROPERTY', 'B-COLOR', 'I-COLOR', 'B-SHAPE', 'I-SHAPE', 'B-SIZE', 'I-SIZE']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ner_tags = [\n",
    "\"MAT\",\n",
    "\"NMAT\",\n",
    "\"DIMENSION\",\n",
    "\"WEIGHT\",\n",
    "\"TARGET_USER\",\n",
    "\"PROPERTY\",\n",
    "\"COLOR\",\n",
    "\"SHAPE\",\n",
    "\"SIZE\",\n",
    "]\n",
    "\n",
    "processed_ner_tags = ['O']\n",
    "for tag in ner_tags:\n",
    "        processed_ner_tags.extend([f\"B-{tag}\", f\"I-{tag}\"])\n",
    "\n",
    "print(processed_ner_tags)\n",
    "print(len(processed_ner_tags))\n",
    "\n",
    "ner_tags_2_number = {t: i for (i, t) in enumerate(processed_ner_tags)}\n",
    "number_2_ner_tags = {t: i for (t, i) in enumerate(ner_tags_2_number)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "f8567698-a512-4a5f-8a11-3e24826f59f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3310 entries, 0 to 3309\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  3310 non-null   object\n",
      " 1   locs      3310 non-null   object\n",
      " 2   words     3310 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 77.7+ KB\n"
     ]
    }
   ],
   "source": [
    "raw_dataset = pd.read_excel(\"../data/raw_data_restore_uppercase.xlsx\")\n",
    "raw_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "8386b037-2702-4110-9f60-531c29090b99",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 3310\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 3310\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 3310\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, ClassLabel, Features, Value, Sequence\n",
    "\n",
    "train_dataset = Dataset.from_pandas(raw_dataset)\n",
    "val_dataset = Dataset.from_pandas(raw_dataset)\n",
    "test_dataset = Dataset.from_pandas(raw_dataset)\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "364fb7ec-7cd0-40cc-9f72-6a5808e24e1b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ner_tags_deberta(example):\n",
    "    # print(example['sentence'])\n",
    "    token_input = tokenizer(example['sentence'])\n",
    "    example['tokens'] = tokenizer.convert_ids_to_tokens(\n",
    "        token_input['input_ids'])\n",
    "\n",
    "    # print(example['sentence'])\n",
    "    # print(example['tokens'])\n",
    "    # print(\"len: \", len(example['tokens']))\n",
    "\n",
    "    ner_tags = [0 for token in example['tokens']]\n",
    "    if str(type(example['locs'])) == \"<class 'list'>\":\n",
    "        locs = example['locs']\n",
    "    else:\n",
    "        locs = ast.literal_eval(example['locs'])\n",
    "\n",
    "    locs = [(int(loc[0]), int(loc[1]), loc[2]) for loc in locs]\n",
    "    locs = sorted(locs)\n",
    "    bg_id = 1\n",
    "    pre_loc = 0\n",
    "    text = example['sentence']\n",
    "    for loc in locs:\n",
    "        loc0 = int(loc[0])\n",
    "        loc1 = int(loc[1])\n",
    "\n",
    "        pre_text = text[pre_loc:loc0]\n",
    "        token_input = tokenizer(pre_text)\n",
    "        pre_token = tokenizer.convert_ids_to_tokens(\n",
    "            token_input['input_ids'])\n",
    "\n",
    "        # print(pre_text)\n",
    "        # print(pre_token)\n",
    "        # print(\"len: \", len(pre_token))\n",
    "\n",
    "        bg_id = bg_id + len(pre_token) - 2\n",
    "        pre_loc = loc1\n",
    "\n",
    "        # print(\"bg_id: \", bg_id)\n",
    "\n",
    "        word = example['sentence'][loc0: loc1]\n",
    "        token_input = tokenizer(word)\n",
    "        word_token = tokenizer.convert_ids_to_tokens(token_input['input_ids'])\n",
    "\n",
    "        label_number = ner_tags_2_number[f\"B-{loc[2]}\"]\n",
    "        ner_tags[bg_id] = label_number\n",
    "        bg_id += 1\n",
    "        for idx in range(bg_id, bg_id + len(word_token) - 3):\n",
    "            ner_tags[idx] = label_number + 1\n",
    "        bg_id = bg_id + len(word_token) - 3\n",
    "\n",
    "        # visualize_ner_tags(example['tokens'], ner_tags)\n",
    "\n",
    "    ner_tags[0] = -100\n",
    "    ner_tags[-1] = -100\n",
    "    return ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a9a29d9a-51b2-46c6-912e-008d0b528841",
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"], truncation=True, is_split_into_words=False\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = assign_ner_tags_deberta(examples)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41ef9a7-f856-4021-8dbf-cc64c0936946",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "list_input_ids = []\n",
    "list_token_type_ids = []\n",
    "list_attention_mask = []\n",
    "list_labels = []\n",
    "\n",
    "for index, row in raw_dataset.iterrows():\n",
    "    try:\n",
    "        label = assign_ner_tags_deberta(row)\n",
    "        token_input = tokenizer(row['sentence'])\n",
    "        list_input_ids.append(token_input['input_ids'])\n",
    "        # list_token_type_ids.append(token_input['token_type_ids'])\n",
    "        list_attention_mask.append(token_input['attention_mask'])\n",
    "        list_labels.append(label)\n",
    "    except Exception as error:\n",
    "        # print(error)\n",
    "        print(index)\n",
    "        print(row['sentence'])\n",
    "\n",
    "tokenized_datasets = pd.DataFrame()\n",
    "tokenized_datasets['input_ids'] = pd.Series(list_input_ids)\n",
    "# tokenized_datasets['token_type_ids'] = pd.Series(list_token_type_ids)\n",
    "tokenized_datasets['attention_mask'] = pd.Series(list_attention_mask)\n",
    "tokenized_datasets['labels'] = pd.Series(list_labels)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "val_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "test_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "\n",
    "tokenized_datasets = DatasetDict(\n",
    "    {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset})\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a4b9408c-d703-41f9-99d8-1e6be83bed1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "f1b8fb80-c285-4758-8cdc-f4bb81a39d29",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "3487f6b0-f8ed-4bcd-a118-cd6ff246fe98",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_names = processed_ner_tags\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100]\n",
    "                   for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(\n",
    "        predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "3ee03d98-723f-4245-a531-fcc00aecc62c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.25553276e-02 5.21506935e+00 4.32536978e+00 3.48417824e+01\n",
      " 4.58000849e+01 1.08175439e+01 1.92580893e+00 5.67921053e+01\n",
      " 3.59443704e+01 9.08673684e+00 1.68023980e+01 1.76482614e+00\n",
      " 9.42607556e-01 3.83730441e+01 1.09215587e+02 5.35774578e+01\n",
      " 5.67921053e+01 9.79174229e+01 2.10341131e+02]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def get_class_weight(train_dataset, num_class):\n",
    "    list_label = []\n",
    "    for label in train_dataset['labels']:\n",
    "        for cl in label:\n",
    "            if cl != -100:\n",
    "                list_label.append(cl)\n",
    "    class_weight = compute_class_weight(class_weight='balanced', classes=np.arange(num_class), y=list_label)\n",
    "    return class_weight\n",
    "\n",
    "class_weight = get_class_weight(train_dataset, len(processed_ner_tags))\n",
    "print(class_weight)\n",
    "print(len(class_weight))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "d0f36aa4-2976-4198-9ff9-c1d08c3d2299",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at microsoft/deberta-base were not used when initializing DebertaForTokenClassification: ['lm_predictions.lm_head.bias', 'lm_predictions.lm_head.dense.bias', 'lm_predictions.lm_head.LayerNorm.weight', 'lm_predictions.lm_head.LayerNorm.bias', 'lm_predictions.lm_head.dense.weight', 'deberta.embeddings.position_embeddings.weight']\n",
      "- This IS expected if you are initializing DebertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing DebertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of DebertaForTokenClassification were not initialized from the model checkpoint at microsoft/deberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DebertaConfig {\n",
       "  \"_name_or_path\": \"microsoft/deberta-base\",\n",
       "  \"attention_probs_dropout_prob\": 0.1,\n",
       "  \"hidden_act\": \"gelu\",\n",
       "  \"hidden_dropout_prob\": 0.1,\n",
       "  \"hidden_size\": 768,\n",
       "  \"id2label\": {\n",
       "    \"0\": \"O\",\n",
       "    \"1\": \"B-MAT\",\n",
       "    \"2\": \"I-MAT\",\n",
       "    \"3\": \"B-NMAT\",\n",
       "    \"4\": \"I-NMAT\",\n",
       "    \"5\": \"B-DIMENSION\",\n",
       "    \"6\": \"I-DIMENSION\",\n",
       "    \"7\": \"B-WEIGHT\",\n",
       "    \"8\": \"I-WEIGHT\",\n",
       "    \"9\": \"B-TARGET_USER\",\n",
       "    \"10\": \"I-TARGET_USER\",\n",
       "    \"11\": \"B-PROPERTY\",\n",
       "    \"12\": \"I-PROPERTY\",\n",
       "    \"13\": \"B-COLOR\",\n",
       "    \"14\": \"I-COLOR\",\n",
       "    \"15\": \"B-SHAPE\",\n",
       "    \"16\": \"I-SHAPE\",\n",
       "    \"17\": \"B-SIZE\",\n",
       "    \"18\": \"I-SIZE\"\n",
       "  },\n",
       "  \"initializer_range\": 0.02,\n",
       "  \"intermediate_size\": 3072,\n",
       "  \"label2id\": {\n",
       "    \"B-COLOR\": 13,\n",
       "    \"B-DIMENSION\": 5,\n",
       "    \"B-MAT\": 1,\n",
       "    \"B-NMAT\": 3,\n",
       "    \"B-PROPERTY\": 11,\n",
       "    \"B-SHAPE\": 15,\n",
       "    \"B-SIZE\": 17,\n",
       "    \"B-TARGET_USER\": 9,\n",
       "    \"B-WEIGHT\": 7,\n",
       "    \"I-COLOR\": 14,\n",
       "    \"I-DIMENSION\": 6,\n",
       "    \"I-MAT\": 2,\n",
       "    \"I-NMAT\": 4,\n",
       "    \"I-PROPERTY\": 12,\n",
       "    \"I-SHAPE\": 16,\n",
       "    \"I-SIZE\": 18,\n",
       "    \"I-TARGET_USER\": 10,\n",
       "    \"I-WEIGHT\": 8,\n",
       "    \"O\": 0\n",
       "  },\n",
       "  \"layer_norm_eps\": 1e-07,\n",
       "  \"max_position_embeddings\": 512,\n",
       "  \"max_relative_positions\": -1,\n",
       "  \"model_type\": \"deberta\",\n",
       "  \"num_attention_heads\": 12,\n",
       "  \"num_hidden_layers\": 12,\n",
       "  \"pad_token_id\": 0,\n",
       "  \"pooler_dropout\": 0,\n",
       "  \"pooler_hidden_act\": \"gelu\",\n",
       "  \"pooler_hidden_size\": 768,\n",
       "  \"pos_att_type\": [\n",
       "    \"c2p\",\n",
       "    \"p2c\"\n",
       "  ],\n",
       "  \"position_biased_input\": false,\n",
       "  \"relative_attention\": true,\n",
       "  \"transformers_version\": \"4.30.2\",\n",
       "  \"type_vocab_size\": 0,\n",
       "  \"vocab_size\": 50265\n",
       "}"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers.models.bert import modeling_bert\n",
    "from transformers import DebertaV2ForTokenClassification\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\n",
    "#     model_checkpoint,\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "#     ignore_mismatched_sizes=True\n",
    "# )\n",
    "\n",
    "# model = AutoModelForTokenClassification.from_pretrained(\n",
    "#     model_checkpoint,\n",
    "#     id2label=id2label,\n",
    "#     label2id=label2id,\n",
    "#     ignore_mismatched_sizes=True\n",
    "# )\n",
    "\n",
    "model = CustomDeberta.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    class_weight=class_weight\n",
    ")\n",
    "\n",
    "model.config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "d44f8726-5544-42c7-9dd0-7ed2aa5eae50",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "9724700e-c61f-4b53-9ddd-8889af273d44",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "93dd89ac-cbfc-4348-8261-3c325e204ef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "9745026c-9d6a-4169-bad7-3deafc18ad3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "1ed5d2f0-d398-4fcc-bd44-02062756fcae",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 100\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91a656a6-d0c8-41cd-b841-bff623db0966",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "date_time = datetime.now()\n",
    "format_date = date_time.strftime('%Y-%m-%d')\n",
    "format_time = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "print(f\"Date: {format_date}\")\n",
    "print(f\"Time: {format_time}\")\n",
    "\n",
    "# Replace with desire output dir\n",
    "output_dir = f\"../models/model_from_{format_date}/deberta-base_{format_time}\"\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_score = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(\n",
    "            predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(\n",
    "            labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(\n",
    "            predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        output_ckpt = os.path.join(output_dir, f'epoch_{epoch + 1}')\n",
    "        print(f\"Save model at epoch {epoch + 1}\")\n",
    "        tokenizer.save_pretrained(output_ckpt)\n",
    "        unwrapped_model.save_pretrained(output_ckpt, save_function=accelerator.save)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "867c6ece-9f16-4db7-b010-72c62f008cca",
   "metadata": {},
   "source": [
    "# Inference"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d71bf7c-5d7f-4a95-b5e2-9bd4fe227a06",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import pipeline\n",
    "from collections import defaultdict\n",
    "\n",
    "# Replace this with your own checkpoint\n",
    "model_checkpoint = \"../models/model_from_2023-10-31/deberta-base_11:38:46/epoch_25\"\n",
    "token_classifier = pipeline(\n",
    "    \"ner\", model=model_checkpoint, aggregation_strategy=\"simple\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12dc8fae-c244-4a1f-9700-fff3c7db10ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_description(description):\n",
    "    single_description = description.strip()\n",
    "    new_description = []\n",
    "    last_special = -1\n",
    "    for idx, letter in enumerate(single_description):\n",
    "        if not (('a' <= letter and letter <= 'z') or ('A' <= letter and letter <= 'Z') or ('0' <= letter and letter <= '9') or letter == ' '):\n",
    "            pretext = single_description[last_special + 1:idx].strip()\n",
    "            if pretext != '' and pretext != ' ':\n",
    "                new_description.append(pretext)\n",
    "            new_description.append(letter.strip())\n",
    "            last_special = idx\n",
    "        if idx == len(single_description) - 1:\n",
    "            new_description.append(\n",
    "                single_description[last_special + 1:idx + 1].strip())\n",
    "    return \" \".join(new_description)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7258a77-cc71-4c32-a536-d97e67e557c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "\n",
    "# Replace this description\n",
    "description = '''\n",
    "Unlike other mixed multi - layer memory foam pads that are used to cut corners , our solid memory foam pads are superior in quality and value .\n",
    "'''\n",
    "\n",
    "high_score_ans = defaultdict(set)\n",
    "bullet_points = description.split(\"\\n\")\n",
    "for bullet_point in bullet_points:\n",
    "    bullet_point = preprocess_description(bullet_point)\n",
    "\n",
    "    if bullet_point != \"\":\n",
    "        print(bullet_point)\n",
    "\n",
    "        results = token_classifier(bullet_point)\n",
    "        for res in results:\n",
    "            if res['word'].lower().strip() in ['durable', 'strong', 'heavy-duty', 'heavy duty', 'stability', 'versatile']:\n",
    "                continue\n",
    "            group = res['entity_group']\n",
    "            if res['score'] >= 0.6:\n",
    "                high_score_ans[group].add(res['word'].lower().strip())\n",
    "                \n",
    "new_high_score_ans = defaultdict(list)\n",
    "for key_dict in high_score_ans.keys():\n",
    "    new_high_score_ans[key_dict] = list(high_score_ans[key_dict])\n",
    "\n",
    "print(\"-\"*100)            \n",
    "print(json.dumps(new_high_score_ans, sort_keys=True, indent=4))                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ad72cbd-5750-4aaa-951a-bfd79e438fec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62f6ddcd-aba2-4d45-94f7-9b16a7f53304",
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "model_checkpoint = \"microsoft/deberta-v2-xlarge\"\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one_for_all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

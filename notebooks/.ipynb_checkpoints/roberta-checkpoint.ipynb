{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e0f3ef1c-6fde-4129-b970-acac83ab9c7d",
   "metadata": {},
   "source": [
    "# Comet ml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "ffe1a43f-0bc9-480a-9b4a-9dd2d58d7a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# $ export COMET_API_KEY=\"ZNgNJ1VVgmaAbL0ga1t4mw3JI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "da014dee-fee0-4bea-8fc0-df9c5fc57b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !comet check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b71a53c6-eee5-48db-b81b-d40745ca82bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import comet_ml\n",
    "\n",
    "# comet_ml.init(project_name=\"roberta-base-ner\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b2baa917-bb36-4b18-926b-d0ea35c15c66",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import comet_ml"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b93f2734-2bcb-4ed9-a47c-ef27065eceeb",
   "metadata": {},
   "source": [
    "# Arguments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "d69a1ed5-07eb-4e64-b17f-53271809fdd3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model_checkpoint = \"roberta-base\"\n",
    "SEED = 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faddd3f5-970f-4f8f-88ac-e2f25513cf88",
   "metadata": {},
   "source": [
    "# Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a79ecd8-f512-4ec9-b382-b5fb5ad4d9e5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(model_checkpoint)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb74dd48-fd4d-426e-8d00-ea8c7934ca6e",
   "metadata": {},
   "source": [
    "# Data loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "34200f88-40a7-474f-a4f0-66b05fc7265b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MAT', 'I-MAT', 'B-NMAT', 'I-NMAT', 'B-DIMENSION', 'I-DIMENSION', 'B-WEIGHT', 'I-WEIGHT', 'B-TARGET_USER', 'I-TARGET_USER', 'B-PROPERTY', 'I-PROPERTY', 'B-COLOR', 'I-COLOR', 'B-SHAPE', 'I-SHAPE', 'B-SIZE', 'I-SIZE']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ner_tags = [\n",
    "\"MAT\",\n",
    "\"NMAT\",\n",
    "\"DIMENSION\",\n",
    "\"WEIGHT\",\n",
    "\"TARGET_USER\",\n",
    "\"PROPERTY\",\n",
    "\"COLOR\",\n",
    "\"SHAPE\",\n",
    "\"SIZE\",\n",
    "]\n",
    "\n",
    "processed_ner_tags = ['O']\n",
    "for tag in ner_tags:\n",
    "        processed_ner_tags.extend([f\"B-{tag}\", f\"I-{tag}\"])\n",
    "\n",
    "print(processed_ner_tags)\n",
    "print(len(processed_ner_tags))\n",
    "\n",
    "ner_tags_2_number = {t: i for (i, t) in enumerate(processed_ner_tags)}\n",
    "number_2_ner_tags = {t: i for (t, i) in enumerate(ner_tags_2_number)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "49c8e8ca-d9b3-4756-a8a7-b4090cd978be",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4636 entries, 0 to 4635\n",
      "Data columns (total 3 columns):\n",
      " #   Column    Non-Null Count  Dtype \n",
      "---  ------    --------------  ----- \n",
      " 0   sentence  4636 non-null   object\n",
      " 1   locs      4636 non-null   object\n",
      " 2   words     4636 non-null   object\n",
      "dtypes: object(3)\n",
      "memory usage: 108.8+ KB\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "raw_excel_dataset = pd.read_excel(\"../data/data_from_09_10_2023/raw_data_restore_uppercase_7_11_2023.xlsx\")\n",
    "raw_excel_dataset.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "adbe29a1-5e60-4785-85c1-9ed1564f5ed6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import ast\n",
    "\n",
    "def assign_ner_tags_roberta(example):\n",
    "    token_input = tokenizer(example['sentence'])\n",
    "    example['tokens'] = tokenizer.convert_ids_to_tokens(\n",
    "        token_input['input_ids'])\n",
    "\n",
    "    ner_tags = [0 for token in example['tokens']]\n",
    "    if str(type(example['locs'])) == \"<class 'list'>\":\n",
    "        locs = example['locs']\n",
    "    else:\n",
    "        locs = ast.literal_eval(example['locs'])\n",
    "\n",
    "    locs = [(int(loc[0]), int(loc[1]), loc[2]) for loc in locs]\n",
    "    locs = sorted(locs)\n",
    "    bg_id = 1\n",
    "    pre_loc = 0\n",
    "    text = example['sentence']\n",
    "    for loc in locs:\n",
    "        loc0 = int(loc[0])\n",
    "        loc1 = int(loc[1])\n",
    "\n",
    "        pre_text = text[pre_loc:loc0]\n",
    "        if 0 < loc0 and len(pre_text) > 0 and pre_text[-1] == ' ':\n",
    "            pre_text = text[pre_loc:loc0 - 1]\n",
    "        token_input = tokenizer(pre_text)\n",
    "        pre_token = tokenizer.convert_ids_to_tokens(\n",
    "            token_input['input_ids'])\n",
    "        bg_id = bg_id + len(pre_token) - 2\n",
    "        pre_loc = loc1\n",
    "\n",
    "        word = example['sentence'][loc0: loc1].strip()\n",
    "        if loc0 > 0 and example['sentence'][loc0 - 1] == ' ':\n",
    "            word = \" \" + word\n",
    "        token_input = tokenizer(word)\n",
    "        word_token = tokenizer.convert_ids_to_tokens(token_input['input_ids'])\n",
    "\n",
    "        label_number = ner_tags_2_number[f\"B-{loc[2]}\"]\n",
    "        ner_tags[bg_id] = label_number\n",
    "        bg_id += 1\n",
    "        for idx in range(bg_id, bg_id + len(word_token) - 3):\n",
    "            ner_tags[idx] = label_number + 1\n",
    "        bg_id = bg_id + len(word_token) - 3\n",
    "\n",
    "        # visualize_ner_tags(example['tokens'], ner_tags)\n",
    "\n",
    "    ner_tags[0] = -100\n",
    "    ner_tags[-1] = -100\n",
    "    return ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "9a20d79e-5537-41da-94b7-66c49d583a11",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from datasets import Dataset, DatasetDict, ClassLabel, Features, Value, Sequence\n",
    "\n",
    "list_input_ids = []\n",
    "list_attention_mask = []\n",
    "list_labels = []\n",
    "\n",
    "for index, row in raw_excel_dataset.iterrows():\n",
    "    try:\n",
    "        label = assign_ner_tags_roberta(row)\n",
    "        token_input = tokenizer(row['sentence'])\n",
    "        list_input_ids.append(token_input['input_ids'])\n",
    "        list_attention_mask.append(token_input['attention_mask'])\n",
    "        list_labels.append(label)\n",
    "    except Exception as error:\n",
    "        print(error)\n",
    "        break\n",
    "        print(index)\n",
    "        print(row['sentence'])\n",
    "\n",
    "tokenized_datasets = pd.DataFrame()\n",
    "tokenized_datasets['input_ids'] = pd.Series(list_input_ids)\n",
    "tokenized_datasets['attention_mask'] = pd.Series(list_attention_mask)\n",
    "tokenized_datasets['labels'] = pd.Series(list_labels)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(tokenized_datasets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "c62f6e5f-d80f-40d3-a9d4-1f3c24a64619",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 3708\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 928\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_datasets = train_dataset.train_test_split(test_size=0.2, shuffle=True, seed=SEED)\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "7d614cde-7b24-4b68-8329-b2ee7fcdd0a0",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=32,\n",
    ")\n",
    "test_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=32\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "944dc69c-2a5a-412d-ad6e-42b0a20ac31d",
   "metadata": {},
   "source": [
    "# Train model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "c74c316a-e2e6-435f-a596-92ebd61ad12f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ed7d303-d16f-4018-9f69-6c3d286d0315",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.41371359e-02 4.20133836e+00 5.68787748e+00 1.25596571e+01\n",
      " 4.60058156e+01 5.64163457e+00 9.40060130e-01 2.22054737e+01\n",
      " 1.26358917e+01 7.61852940e+00 1.87124778e+01 2.12046158e+00\n",
      " 1.36576228e+00 1.98736340e+01 1.00325935e+02 3.51352432e+01\n",
      " 4.08188854e+01 5.01629677e+01 1.57114201e+02]\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from collections import Counter\n",
    "import numpy as np\n",
    "\n",
    "def get_class_weight(train_dataset, num_class):\n",
    "    list_label = []\n",
    "    for label in train_dataset['labels']:\n",
    "        for cl in label:\n",
    "            if cl != -100:\n",
    "                list_label.append(cl)\n",
    "    class_weight = compute_class_weight(class_weight='balanced', classes=np.arange(num_class), y=list_label)\n",
    "    return class_weight\n",
    "\n",
    "class_weight = get_class_weight(tokenized_datasets['train'], len(processed_ner_tags))\n",
    "print(class_weight)\n",
    "print(len(class_weight))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e6b52a4-320b-46ed-8810-f20e01e03c34",
   "metadata": {},
   "source": [
    "## Model classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "5c08315b-93a9-4f4f-8c85-b13e93d0893f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://www.kaggle.com/code/wuharlem/simple-bert-w-hinge-loss\n",
    "\n",
    "from transformers import RobertaForTokenClassification, DebertaV2ForTokenClassification\n",
    "from typing import List, Optional, Tuple, Union\n",
    "from transformers.modeling_outputs import TokenClassifierOutput\n",
    "from torch.nn import CrossEntropyLoss\n",
    "import torch\n",
    " \n",
    "class CustomRoberta(RobertaForTokenClassification):\n",
    "  def __init__(self, config, class_weight=None):\n",
    "    super().__init__(config)\n",
    "    self.class_weight = torch.tensor(class_weight, dtype=torch.float32).to('cuda' if torch.cuda.is_available() else 'cpu') if class_weight != None else None\n",
    "    \n",
    "  def forward(\n",
    "        self,\n",
    "        input_ids: Optional[torch.LongTensor] = None,\n",
    "        attention_mask: Optional[torch.FloatTensor] = None,\n",
    "        token_type_ids: Optional[torch.LongTensor] = None,\n",
    "        position_ids: Optional[torch.LongTensor] = None,\n",
    "        head_mask: Optional[torch.FloatTensor] = None,\n",
    "        inputs_embeds: Optional[torch.FloatTensor] = None,\n",
    "        labels: Optional[torch.LongTensor] = None,\n",
    "        output_attentions: Optional[bool] = None,\n",
    "        output_hidden_states: Optional[bool] = None,\n",
    "        return_dict: Optional[bool] = None,\n",
    "    ) -> Union[Tuple[torch.Tensor], TokenClassifierOutput]:\n",
    "        r\"\"\"\n",
    "        labels (`torch.LongTensor` of shape `(batch_size, sequence_length)`, *optional*):\n",
    "            Labels for computing the token classification loss. Indices should be in `[0, ..., config.num_labels - 1]`.\n",
    "        \"\"\"\n",
    "        return_dict = return_dict if return_dict is not None else self.config.use_return_dict\n",
    "\n",
    "        outputs = self.roberta(\n",
    "            input_ids,\n",
    "            attention_mask=attention_mask,\n",
    "            token_type_ids=token_type_ids,\n",
    "            position_ids=position_ids,\n",
    "            head_mask=head_mask,\n",
    "            inputs_embeds=inputs_embeds,\n",
    "            output_attentions=output_attentions,\n",
    "            output_hidden_states=output_hidden_states,\n",
    "            return_dict=return_dict,\n",
    "        )\n",
    "\n",
    "        sequence_output = outputs[0]\n",
    "        \n",
    "        sequence_output = self.dropout(sequence_output)\n",
    "        logits = self.classifier(sequence_output)\n",
    "\n",
    "        loss = None\n",
    "        if labels is not None:\n",
    "            # move labels to correct device to enable model parallelism\n",
    "            labels = labels.to(logits.device)\n",
    "            if self.class_weight is None:\n",
    "                loss_fct = CrossEntropyLoss()\n",
    "            else:\n",
    "                loss_fct = CrossEntropyLoss(weight=self.class_weight)\n",
    "                \n",
    "            loss = loss_fct(logits.view(-1, self.num_labels), labels.view(-1))\n",
    "            \n",
    "        if not return_dict:\n",
    "            output = (logits,) + outputs[2:]\n",
    "            return ((loss,) + output) if loss is not None else output\n",
    "\n",
    "        return TokenClassifierOutput(\n",
    "            loss=loss,\n",
    "            logits=logits,\n",
    "            hidden_states=outputs.hidden_states,\n",
    "            attentions=outputs.attentions,\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a76e7ca6-c11d-495e-8913-d46a638ea008",
   "metadata": {},
   "source": [
    "## Setup training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "52b2399f-a635-41f4-81ac-904b94e3d065",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing CustomRoberta: ['lm_head.dense.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.weight', 'lm_head.bias', 'lm_head.layer_norm.bias']\n",
      "- This IS expected if you are initializing CustomRoberta from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing CustomRoberta from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of CustomRoberta were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RobertaConfig {\n",
      "  \"_name_or_path\": \"roberta-base\",\n",
      "  \"architectures\": [\n",
      "    \"RobertaForMaskedLM\"\n",
      "  ],\n",
      "  \"attention_probs_dropout_prob\": 0.1,\n",
      "  \"bos_token_id\": 0,\n",
      "  \"classifier_dropout\": null,\n",
      "  \"eos_token_id\": 2,\n",
      "  \"hidden_act\": \"gelu\",\n",
      "  \"hidden_dropout_prob\": 0.1,\n",
      "  \"hidden_size\": 768,\n",
      "  \"id2label\": {\n",
      "    \"0\": \"O\",\n",
      "    \"1\": \"B-MAT\",\n",
      "    \"2\": \"I-MAT\",\n",
      "    \"3\": \"B-NMAT\",\n",
      "    \"4\": \"I-NMAT\",\n",
      "    \"5\": \"B-DIMENSION\",\n",
      "    \"6\": \"I-DIMENSION\",\n",
      "    \"7\": \"B-WEIGHT\",\n",
      "    \"8\": \"I-WEIGHT\",\n",
      "    \"9\": \"B-TARGET_USER\",\n",
      "    \"10\": \"I-TARGET_USER\",\n",
      "    \"11\": \"B-PROPERTY\",\n",
      "    \"12\": \"I-PROPERTY\",\n",
      "    \"13\": \"B-COLOR\",\n",
      "    \"14\": \"I-COLOR\",\n",
      "    \"15\": \"B-SHAPE\",\n",
      "    \"16\": \"I-SHAPE\",\n",
      "    \"17\": \"B-SIZE\",\n",
      "    \"18\": \"I-SIZE\"\n",
      "  },\n",
      "  \"initializer_range\": 0.02,\n",
      "  \"intermediate_size\": 3072,\n",
      "  \"label2id\": {\n",
      "    \"B-COLOR\": 13,\n",
      "    \"B-DIMENSION\": 5,\n",
      "    \"B-MAT\": 1,\n",
      "    \"B-NMAT\": 3,\n",
      "    \"B-PROPERTY\": 11,\n",
      "    \"B-SHAPE\": 15,\n",
      "    \"B-SIZE\": 17,\n",
      "    \"B-TARGET_USER\": 9,\n",
      "    \"B-WEIGHT\": 7,\n",
      "    \"I-COLOR\": 14,\n",
      "    \"I-DIMENSION\": 6,\n",
      "    \"I-MAT\": 2,\n",
      "    \"I-NMAT\": 4,\n",
      "    \"I-PROPERTY\": 12,\n",
      "    \"I-SHAPE\": 16,\n",
      "    \"I-SIZE\": 18,\n",
      "    \"I-TARGET_USER\": 10,\n",
      "    \"I-WEIGHT\": 8,\n",
      "    \"O\": 0\n",
      "  },\n",
      "  \"layer_norm_eps\": 1e-05,\n",
      "  \"max_position_embeddings\": 514,\n",
      "  \"model_type\": \"roberta\",\n",
      "  \"num_attention_heads\": 12,\n",
      "  \"num_hidden_layers\": 12,\n",
      "  \"pad_token_id\": 1,\n",
      "  \"position_embedding_type\": \"absolute\",\n",
      "  \"transformers_version\": \"4.30.2\",\n",
      "  \"type_vocab_size\": 1,\n",
      "  \"use_cache\": true,\n",
      "  \"vocab_size\": 50265\n",
      "}\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers.models.bert import modeling_bert\n",
    "from transformers import RobertaForTokenClassification, DebertaV2ForTokenClassification\n",
    "\n",
    "label_names = processed_ner_tags\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "model = CustomRoberta.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True,\n",
    "    # class_weight=class_weight\n",
    ")\n",
    "\n",
    "print(model.config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "3017f8bf-b894-4276-816d-34a3cb7e15f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "import numpy as np\n",
    "from torch.optim import AdamW\n",
    "from transformers import get_scheduler\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)\n",
    "\n",
    "num_train_epochs = 1000\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "cd464490-cfce-4968-a24b-8985eabb42c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, test_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, test_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "e7c381da-3959-4a0b-8699-cdc5bcc6e4a3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Comet.ml Experiment Summary\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m ---------------------------------------------------------------------------------------\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Data:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     display_summary_level : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     url                   : https://www.comet.com/luunvt/roberta-base-ner-attribution-extraction/a7472c8e642844f4a2d2d146f4f7c56d\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Metrics [count] (min, max):\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_accuracy   : 0.9283927696552435\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_f1         : 0.5101643980908609\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_precision  : 0.563231850117096\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     test_recall     : 0.4662358642972536\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     train_loss [22] : (0.11475483328104019, 2.6202428340911865)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Parameters:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     SEED             : 7\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model            : roberta-base\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_epochs       : 1000\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_test_sample  : 928\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     num_train_sample : 3708\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     optimizer        : adamW\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     use_class_weight : True\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m   Uploads:\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-environment-definition : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-info                   : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     conda-specification          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     environment details          : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     filename                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git metadata                 : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     git-patch (uncompressed)     : 1 (752.60 KB)\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     installed packages           : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     model graph                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     notebook                     : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     os packages                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m     source_code                  : 1\n",
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m \n",
      "\u001b[38;5;36m─────────────────────────────────────────────── \u001b[0m\u001b[1;38;5;36mNew Comet feature!\u001b[0m\u001b[38;5;36m ───────────────────────────────────────────────\u001b[0m\n",
      "Log your models to better track, deploy, share, and reproduce your work using: 'comet_ml.integration.pytorch.log_model'.\n",
      "Learn more at: https://comet.com/docs/v2/pytorch_log_model\n",
      "\n",
      "Hide this message by setting environment variable \"COMET_DISABLE_ANNOUNCEMENT=1\" \n",
      "\u001b[38;5;36m──────────────────────────────────────────────────────────────────────────────────────────────────────────────────\u001b[0m\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m As you are running in a Jupyter environment, you will need to call `experiment.end()` when finished to ensure all metrics and code are logged before exiting.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1;38;5;39mCOMET INFO:\u001b[0m Experiment is live on comet.com https://www.comet.com/luunvt/roberta-base-ner-attribution-extraction/dfe6a5460b1a4524a72010956b710d64\n",
      "\n",
      "\u001b[1;38;5;214mCOMET WARNING:\u001b[0m unable to find caller source code in a jupyter notebook; ignoring\n"
     ]
    }
   ],
   "source": [
    "from comet_ml import Experiment, ExistingExperiment\n",
    "from comet_ml.integration.pytorch import log_model\n",
    "import comet_ml\n",
    "\n",
    "experiment = Experiment(\n",
    "    api_key=\"ZNgNJ1VVgmaAbL0ga1t4mw3JI\",\n",
    "    project_name=\"roberta-base-ner-attribution-extraction\",\n",
    "    workspace=\"luunvt\",\n",
    "    log_code=True\n",
    ")\n",
    "\n",
    "hyper_params = {\n",
    "    \"model\": model_checkpoint, \n",
    "    \"num_epochs\": num_train_epochs, \n",
    "    \"optimizer\": \"adamW\",\n",
    "    \"use_class_weight\": True,\n",
    "    \"num_train_sample\": len(tokenized_datasets[\"train\"]),\n",
    "    \"num_test_sample\": len(tokenized_datasets[\"test\"]),\n",
    "    \"SEED\": SEED\n",
    "}\n",
    "experiment.log_parameters(hyper_params)\n",
    "experiment.add_tags([\"roberta-ner-classweight\"])\n",
    "experiment.set_model_graph(model)\n",
    "experiment.log_code()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "e497f154-3634-4f43-8aa8-bd3e63ca2ffc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# def post_process_logit(predictions, labels, accelerator):\n",
    "#     predictions = accelerator.pad_across_processes(\n",
    "#         predictions, dim=1, pad_index=-100)\n",
    "#     labels = accelerator.pad_across_processes(\n",
    "#         labels, dim=1, pad_index=-100)\n",
    "\n",
    "#     predictions_gathered = accelerator.gather(predictions)\n",
    "#     labels_gathered = accelerator.gather(labels)\n",
    "#     return predictions_gathered, labels_gathered\n",
    "    \n",
    "# def compute_metric(metric, accelerator, experiment, mode):\n",
    "#     with experiment.train() if mode=='train' else experiment.test():\n",
    "#         true_predictions, true_labels = postprocess(\n",
    "#             predictions_gathered, labels_gathered)\n",
    "#         metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "#         results = metric.compute()\n",
    "#         if experiment:\n",
    "#             experiment.set_epoch(epoch)\n",
    "#             experiment.log_metric(\"precision\", results[\"overall_precision\"])\n",
    "#             experiment.log_metric(\"recall\", results[\"overall_recall\"])\n",
    "#             experiment.log_metric(\"f1\", results[\"overall_f1\"])\n",
    "#             experiment.log_metric(\"accuracy\", results[\"overall_accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cc0fb11-dd79-422a-82f7-3f883314e99b",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Date: 2023-11-08\n",
      "Time: 09:42:48\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/tanluuuuuuu/miniconda3/envs/one_for_all/lib/python3.8/site-packages/seqeval/metrics/v1.py:57: UndefinedMetricWarning: Recall and F-score are ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
      "  _warn_prf(average, modifier, msg_start, len(result))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch 0: {'precision': 0.460967993754879, 'recall': 0.35369871218927823, 'f1': 0.40027114048466367, 'accuracy': 0.9155514298238828}\n",
      "Save best f1 model at epoch 0 with better f1 score 0.40027114048466367\n",
      "epoch 1: {'precision': 0.7103825136612022, 'recall': 0.5880452342487884, 'f1': 0.6434505921866713, 'accuracy': 0.9406410355586499}\n",
      "Save best f1 model at epoch 1 with better f1 score 0.6434505921866713\n",
      "epoch 2: {'precision': 0.7634660421545667, 'recall': 0.6336248785228377, 'f1': 0.6925119490175251, 'accuracy': 0.9439416208968309}\n",
      "Save best f1 model at epoch 2 with better f1 score 0.6925119490175251\n",
      "epoch 3: {'precision': 0.7708821233411397, 'recall': 0.7008516678495387, 'f1': 0.7342007434944238, 'accuracy': 0.9555968128722828}\n",
      "Save best f1 model at epoch 3 with better f1 score 0.7342007434944238\n",
      "epoch 4: {'precision': 0.7919594067135051, 'recall': 0.7129304286718201, 'f1': 0.750369822485207, 'accuracy': 0.9560093860395554}\n",
      "Save best f1 model at epoch 4 with better f1 score 0.750369822485207\n"
     ]
    }
   ],
   "source": [
    "import comet_ml\n",
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "import logging\n",
    "\n",
    "date_time = datetime.now()\n",
    "format_date = date_time.strftime('%Y-%m-%d')\n",
    "format_time = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "print(f\"Date: {format_date}\")\n",
    "print(f\"Time: {format_time}\")\n",
    "\n",
    "output_dir = f\"../models/model_from_{format_date}/roberta-base_{format_time}\"\n",
    "\n",
    "best_f1_score = 0\n",
    "    \n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    with experiment.train():\n",
    "        model.train()\n",
    "        for batch in train_dataloader:\n",
    "            outputs = model(**batch)\n",
    "            loss = outputs.loss\n",
    "            accelerator.backward(loss)\n",
    "    \n",
    "            optimizer.step()\n",
    "            lr_scheduler.step()\n",
    "            optimizer.zero_grad()\n",
    "    # Evaluation\n",
    "    with experiment.test():\n",
    "        model.eval()\n",
    "        for batch in test_dataloader:\n",
    "            with torch.no_grad():\n",
    "                outputs = model(**batch)\n",
    "    \n",
    "            predictions = outputs.logits.argmax(dim=-1)\n",
    "            labels = batch[\"labels\"]\n",
    "    \n",
    "            # Necessary to pad predictions and labels for being gathered\n",
    "            predictions = accelerator.pad_across_processes(\n",
    "                predictions, dim=1, pad_index=-100)\n",
    "            labels = accelerator.pad_across_processes(\n",
    "                labels, dim=1, pad_index=-100)\n",
    "    \n",
    "            predictions_gathered = accelerator.gather(predictions)\n",
    "            labels_gathered = accelerator.gather(labels)\n",
    "    \n",
    "            true_predictions, true_labels = postprocess(\n",
    "                predictions_gathered, labels_gathered)\n",
    "            metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "    \n",
    "        results = metric.compute()\n",
    "        print(\n",
    "            f\"epoch {epoch}:\",\n",
    "            {\n",
    "                key: results[f\"overall_{key}\"]\n",
    "                for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "            },\n",
    "        )\n",
    "    \n",
    "        if experiment:\n",
    "            experiment.set_epoch(epoch)\n",
    "            experiment.log_metric(\"precision\", results[\"overall_precision\"])\n",
    "            experiment.log_metric(\"recall\", results[\"overall_recall\"])\n",
    "            experiment.log_metric(\"f1\", results[\"overall_f1\"])\n",
    "            experiment.log_metric(\"accuracy\", results[\"overall_accuracy\"])\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    if accelerator.is_main_process and results[f\"overall_f1\"] > best_f1_score:\n",
    "        output_ckpt = os.path.join(output_dir, f'best_f1')\n",
    "        best_f1_score = results[f\"overall_f1\"]\n",
    "        print(\n",
    "            f\"Save best f1 model at epoch {epoch} with better f1 score {best_f1_score}\")\n",
    "        tokenizer.save_pretrained(output_ckpt)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            output_ckpt, save_function=accelerator.save)\n",
    "    if (epoch + 1) % 100 == 0:\n",
    "        output_ckpt = os.path.join(output_dir, f'epoch_{epoch + 1}')\n",
    "        print(f\"Save model at epoch {epoch + 1}\")\n",
    "        tokenizer.save_pretrained(output_ckpt)\n",
    "        unwrapped_model.save_pretrained(\n",
    "            output_ckpt, save_function=accelerator.save)\n",
    "experiment.end()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25793cce-8489-422c-a2bc-0bbb7e49692c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

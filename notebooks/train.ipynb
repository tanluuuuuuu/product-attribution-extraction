{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Check CUDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'pandas'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[1;32m/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/gitclone/attribute_extraction/notebooks/train.ipynb Cell 2\u001b[0m line \u001b[0;36m2\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/gitclone/attribute_extraction/notebooks/train.ipynb#W0sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mtorch\u001b[39;00m\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/gitclone/attribute_extraction/notebooks/train.ipynb#W0sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mpandas\u001b[39;00m \u001b[39mas\u001b[39;00m \u001b[39mpd\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/gitclone/attribute_extraction/notebooks/train.ipynb#W0sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mimport\u001b[39;00m \u001b[39mast\u001b[39;00m\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/tanluuuuuuu/Desktop/luunvt/direct_indirect/gitclone/attribute_extraction/notebooks/train.ipynb#W0sZmlsZQ%3D%3D?line=4'>5</a>\u001b[0m \u001b[39mprint\u001b[39m(\u001b[39m\"\u001b[39m\u001b[39mCUDA: \u001b[39m\u001b[39m\"\u001b[39m, torch\u001b[39m.\u001b[39mcuda\u001b[39m.\u001b[39mis_available())\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'pandas'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import pandas as pd\n",
    "import ast\n",
    "\n",
    "print(\"CUDA: \", torch.cuda.is_available())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data and defined label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['O', 'B-MAT', 'I-MAT', 'B-NMAT', 'I-NMAT', 'B-DIMENSION', 'I-DIMENSION', 'B-WEIGHT', 'I-WEIGHT', 'B-TARGET_USER', 'I-TARGET_USER', 'B-PROPERTY', 'I-PROPERTY', 'B-COLOR', 'I-COLOR', 'B-SHAPE', 'I-SHAPE', 'B-SIZE', 'I-SIZE']\n",
      "19\n"
     ]
    }
   ],
   "source": [
    "ner_tags = [\n",
    "\"MAT\",\n",
    "\"NMAT\",\n",
    "\"DIMENSION\",\n",
    "\"WEIGHT\",\n",
    "\"TARGET_USER\",\n",
    "\"PROPERTY\",\n",
    "\"COLOR\",\n",
    "\"SHAPE\",\n",
    "\"SIZE\",\n",
    "]\n",
    "\n",
    "ner_tags_property = [\n",
    "# \"PROPERTY\"\n",
    "]\n",
    "\n",
    "processed_ner_tags = ['O']\n",
    "for tag in ner_tags:\n",
    "        processed_ner_tags.extend([f\"B-{tag}\", f\"I-{tag}\"])\n",
    "\n",
    "print(processed_ner_tags)\n",
    "print(len(processed_ner_tags))\n",
    "\n",
    "ner_tags_2_number = {t: i for (i, t) in enumerate(processed_ner_tags)}\n",
    "number_2_ner_tags = {t: i for (t, i) in enumerate(ner_tags_2_number)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>locs</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>üê∂ „Äê Support and Piping Design „Äë : Supportive r...</td>\n",
       "      <td>[('45', '57', 'PROPERTY'), ('114', '118', 'TAR...</td>\n",
       "      <td>['raised sides', 'cats', 'dogs', 'pet', 'recta...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>üê∂ „Äê High - Quality Materials „Äë : The inner rin...</td>\n",
       "      <td>[('101', '105', 'MAT'), ('37', '47', 'PROPERTY')]</td>\n",
       "      <td>['wool', 'inner ring']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>üê∂ „Äê Non - Slip Bottom „Äë : The rectangular bed ...</td>\n",
       "      <td>[('4', '21', 'PROPERTY'), ('59', '76', 'PROPER...</td>\n",
       "      <td>['Non - Slip Bottom', 'non - slip bottom', 're...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>üê∂ „Äê Easy to Care „Äë : The pet bed can be machin...</td>\n",
       "      <td>[('40', '54', 'PROPERTY'), ('25', '28', 'TARGE...</td>\n",
       "      <td>['machine washed', 'pet']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>üê∂ „Äê Pls Noted „Äë : As the bed is vacuum - packe...</td>\n",
       "      <td>[('177', '180', 'TARGET_USER')]</td>\n",
       "      <td>['pet']</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  \\\n",
       "0  üê∂ „Äê Support and Piping Design „Äë : Supportive r...   \n",
       "1  üê∂ „Äê High - Quality Materials „Äë : The inner rin...   \n",
       "2  üê∂ „Äê Non - Slip Bottom „Äë : The rectangular bed ...   \n",
       "3  üê∂ „Äê Easy to Care „Äë : The pet bed can be machin...   \n",
       "4  üê∂ „Äê Pls Noted „Äë : As the bed is vacuum - packe...   \n",
       "\n",
       "                                                locs  \\\n",
       "0  [('45', '57', 'PROPERTY'), ('114', '118', 'TAR...   \n",
       "1  [('101', '105', 'MAT'), ('37', '47', 'PROPERTY')]   \n",
       "2  [('4', '21', 'PROPERTY'), ('59', '76', 'PROPER...   \n",
       "3  [('40', '54', 'PROPERTY'), ('25', '28', 'TARGE...   \n",
       "4                    [('177', '180', 'TARGET_USER')]   \n",
       "\n",
       "                                               words  \n",
       "0  ['raised sides', 'cats', 'dogs', 'pet', 'recta...  \n",
       "1                             ['wool', 'inner ring']  \n",
       "2  ['Non - Slip Bottom', 'non - slip bottom', 're...  \n",
       "3                          ['machine washed', 'pet']  \n",
       "4                                            ['pet']  "
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "raw_dataset = pd.read_excel(\"../data/raw_data_restore_uppercase.xlsx\")\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['sentence', 'locs', 'words'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset, DatasetDict, ClassLabel, Features, Value, Sequence\n",
    "\n",
    "train_dataset = Dataset.from_pandas(raw_dataset)\n",
    "val_dataset = Dataset.from_pandas(raw_dataset)\n",
    "test_dataset = Dataset.from_pandas(raw_dataset)\n",
    "\n",
    "raw_datasets = DatasetDict(\n",
    "    {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset})\n",
    "raw_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_ner_tags(words, labels):\n",
    "    line1 = \"\"\n",
    "    line2 = \"\"\n",
    "    for word, label in zip(words, labels):\n",
    "        # print(word, label)\n",
    "        label = str(label)\n",
    "        max_length = max(len(word), len(label))\n",
    "        line1 += word + \" \" * (max_length - len(word) + 1)\n",
    "        line2 += label + \" \" * (max_length - len(label) + 1)\n",
    "    print(line1)\n",
    "    print(line2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "def assign_ner_tags_roberta(example):\n",
    "\n",
    "    token_input = tokenizer(example['sentence'])\n",
    "    example['tokens'] = tokenizer.convert_ids_to_tokens(\n",
    "        token_input['input_ids'])\n",
    "\n",
    "    ner_tags = [0 for token in example['tokens']]\n",
    "    if str(type(example['locs'])) == \"<class 'list'>\":\n",
    "        locs = example['locs']\n",
    "    else:\n",
    "        locs = ast.literal_eval(example['locs'])\n",
    "\n",
    "    locs = [(int(loc[0]), int(loc[1]), loc[2]) for loc in locs]\n",
    "    locs = sorted(locs)\n",
    "    bg_id = 1\n",
    "    pre_loc = 0\n",
    "    text = example['sentence']\n",
    "    for loc in locs:\n",
    "        loc0 = int(loc[0])\n",
    "        loc1 = int(loc[1])\n",
    "\n",
    "        pre_text = text[pre_loc:loc0]\n",
    "        if 0 < loc0 and len(pre_text) > 0 and pre_text[-1] == ' ':\n",
    "            pre_text = text[pre_loc:loc0 - 1]\n",
    "        token_input = tokenizer(pre_text)\n",
    "        pre_token = tokenizer.convert_ids_to_tokens(\n",
    "            token_input['input_ids'])\n",
    "        bg_id = bg_id + len(pre_token) - 2\n",
    "        pre_loc = loc1\n",
    "\n",
    "        word = example['sentence'][loc0: loc1].strip()\n",
    "        if loc0 > 0 and example['sentence'][loc0 - 1] == ' ':\n",
    "            word = \" \" + word\n",
    "        token_input = tokenizer(word)\n",
    "        word_token = tokenizer.convert_ids_to_tokens(token_input['input_ids'])\n",
    "\n",
    "        label_number = ner_tags_2_number[f\"B-{loc[2]}\"]\n",
    "        ner_tags[bg_id] = label_number\n",
    "        bg_id += 1\n",
    "        for idx in range(bg_id, bg_id + len(word_token) - 3):\n",
    "            ner_tags[idx] = label_number + 1\n",
    "        bg_id = bg_id + len(word_token) - 3\n",
    "\n",
    "        # visualize_ner_tags(example['tokens'], ner_tags)\n",
    "\n",
    "    ner_tags[0] = -100\n",
    "    ner_tags[-1] = -100\n",
    "    return ner_tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Safe Design : The four legs are welded with x - shaped rods on both top and base to ensure stability , and each end table leg has a non - slip rubber pad for floor protection and avoid noising your pets .\n",
      "--------------------------------------------------\n",
      "{'input_ids': [0, 32356, 7438, 4832, 20, 237, 5856, 32, 36736, 196, 19, 3023, 111, 14216, 33920, 15, 258, 299, 8, 1542, 7, 1306, 5443, 2156, 8, 349, 253, 2103, 2985, 34, 10, 786, 111, 9215, 11283, 11212, 13, 1929, 2591, 8, 1877, 117, 3009, 110, 10029, 479, 2], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n",
      "--------------------------------------------------\n",
      "['<s>', 'Safe', 'ƒ†Design', 'ƒ†:', 'ƒ†The', 'ƒ†four', 'ƒ†legs', 'ƒ†are', 'ƒ†weld', 'ed', 'ƒ†with', 'ƒ†x', 'ƒ†-', 'ƒ†shaped', 'ƒ†rods', 'ƒ†on', 'ƒ†both', 'ƒ†top', 'ƒ†and', 'ƒ†base', 'ƒ†to', 'ƒ†ensure', 'ƒ†stability', 'ƒ†,', 'ƒ†and', 'ƒ†each', 'ƒ†end', 'ƒ†table', 'ƒ†leg', 'ƒ†has', 'ƒ†a', 'ƒ†non', 'ƒ†-', 'ƒ†slip', 'ƒ†rubber', 'ƒ†pad', 'ƒ†for', 'ƒ†floor', 'ƒ†protection', 'ƒ†and', 'ƒ†avoid', 'ƒ†no', 'ising', 'ƒ†your', 'ƒ†pets', 'ƒ†.', '</s>']\n",
      "<s>  Safe ƒ†Design ƒ†: ƒ†The ƒ†four ƒ†legs ƒ†are ƒ†weld ed ƒ†with ƒ†x ƒ†- ƒ†shaped ƒ†rods ƒ†on ƒ†both ƒ†top ƒ†and ƒ†base ƒ†to ƒ†ensure ƒ†stability ƒ†, ƒ†and ƒ†each ƒ†end ƒ†table ƒ†leg ƒ†has ƒ†a ƒ†non ƒ†- ƒ†slip ƒ†rubber ƒ†pad ƒ†for ƒ†floor ƒ†protection ƒ†and ƒ†avoid ƒ†no ising ƒ†your ƒ†pets ƒ†. </s> \n",
      "-100 0    0       0  0    11    12    0    11    12 0     11 12 12      12    0   0     0    0    0     0   0       0          0  0    0     0    0      0    0    0  11   12 12    1       0    0    0      0           0    0      0   0     0     0     0  -100 \n"
     ]
    }
   ],
   "source": [
    "id = 1571\n",
    "print(raw_datasets['train'][id]['sentence'])\n",
    "print(\"-\"*50)\n",
    "\n",
    "token_input = tokenizer(raw_datasets['train'][id]['sentence'])\n",
    "print(token_input)\n",
    "print(\"-\"*50)\n",
    "\n",
    "words = tokenizer.convert_ids_to_tokens(token_input['input_ids'])\n",
    "print(words)\n",
    "labels = assign_ner_tags_roberta(raw_datasets['train'][id])\n",
    "\n",
    "visualize_ner_tags(words, labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preprocessing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenize_and_align_labels(examples):\n",
    "    tokenized_inputs = tokenizer(\n",
    "        examples[\"sentence\"], truncation=True, is_split_into_words=False\n",
    "    )\n",
    "    tokenized_inputs[\"labels\"] = assign_ner_tags_bert(examples)\n",
    "    return tokenized_inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['input_ids', 'attention_mask', 'labels'],\n",
       "        num_rows: 2784\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "\n",
    "list_input_ids = []\n",
    "list_token_type_ids = []\n",
    "list_attention_mask = []\n",
    "list_labels = []\n",
    "\n",
    "for index, row in raw_dataset.iterrows():\n",
    "    try:\n",
    "        label = assign_ner_tags_roberta(row)\n",
    "        token_input = tokenizer(row['sentence'])\n",
    "        list_input_ids.append(token_input['input_ids'])\n",
    "        # list_token_type_ids.append(token_input['token_type_ids'])\n",
    "        list_attention_mask.append(token_input['attention_mask'])\n",
    "        list_labels.append(label)\n",
    "    except Exception as error:\n",
    "        # print(error)\n",
    "        print(index)\n",
    "        print(row['sentence'])\n",
    "\n",
    "tokenized_datasets = pd.DataFrame()\n",
    "tokenized_datasets['input_ids'] = pd.Series(list_input_ids)\n",
    "# tokenized_datasets['token_type_ids'] = pd.Series(list_token_type_ids)\n",
    "tokenized_datasets['attention_mask'] = pd.Series(list_attention_mask)\n",
    "tokenized_datasets['labels'] = pd.Series(list_labels)\n",
    "\n",
    "train_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "val_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "test_dataset = Dataset.from_pandas(tokenized_datasets)\n",
    "\n",
    "tokenized_datasets = DatasetDict(\n",
    "    {\"train\": train_dataset, \"val\": val_dataset, \"test\": test_dataset})\n",
    "tokenized_datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import DataCollatorForTokenClassification\n",
    "\n",
    "data_collator = DataCollatorForTokenClassification(tokenizer=tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import evaluate\n",
    "\n",
    "metric = evaluate.load(\"seqeval\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "label_names = processed_ner_tags\n",
    "id2label = {i: label for i, label in enumerate(label_names)}\n",
    "label2id = {v: k for k, v in id2label.items()}\n",
    "\n",
    "\n",
    "def compute_metrics(eval_preds):\n",
    "    logits, labels = eval_preds\n",
    "    predictions = np.argmax(logits, axis=-1)\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100]\n",
    "                   for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    all_metrics = metric.compute(\n",
    "        predictions=true_predictions, references=true_labels)\n",
    "    return {\n",
    "        \"precision\": all_metrics[\"overall_precision\"],\n",
    "        \"recall\": all_metrics[\"overall_recall\"],\n",
    "        \"f1\": all_metrics[\"overall_f1\"],\n",
    "        \"accuracy\": all_metrics[\"overall_accuracy\"],\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at roberta-base were not used when initializing RobertaForTokenClassification: ['lm_head.dense.weight', 'lm_head.layer_norm.bias', 'lm_head.layer_norm.weight', 'lm_head.dense.bias', 'lm_head.bias']\n",
      "- This IS expected if you are initializing RobertaForTokenClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing RobertaForTokenClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of RobertaForTokenClassification were not initialized from the model checkpoint at roberta-base and are newly initialized: ['classifier.weight', 'classifier.bias']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "19"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from transformers import AutoModelForTokenClassification\n",
    "from transformers.models.bert import modeling_bert\n",
    "from transformers import RobertaForTokenClassification\n",
    "\n",
    "model = RobertaForTokenClassification.from_pretrained(\n",
    "    model_checkpoint,\n",
    "    id2label=id2label,\n",
    "    label2id=label2id,\n",
    "    ignore_mismatched_sizes=True\n",
    ")\n",
    "model.config.num_labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"train\"],\n",
    "    shuffle=True,\n",
    "    collate_fn=data_collator,\n",
    "    batch_size=8,\n",
    ")\n",
    "eval_dataloader = DataLoader(\n",
    "    tokenized_datasets[\"test\"], collate_fn=data_collator, batch_size=8\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import AdamW\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=2e-5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from accelerate import Accelerator\n",
    "\n",
    "accelerator = Accelerator()\n",
    "model, optimizer, train_dataloader, eval_dataloader = accelerator.prepare(\n",
    "    model, optimizer, train_dataloader, eval_dataloader\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess(predictions, labels):\n",
    "    predictions = predictions.detach().cpu().clone().numpy()\n",
    "    labels = labels.detach().cpu().clone().numpy()\n",
    "\n",
    "    # Remove ignored index (special tokens) and convert to labels\n",
    "    true_labels = [[label_names[l] for l in label if l != -100] for label in labels]\n",
    "    true_predictions = [\n",
    "        [label_names[p] for (p, l) in zip(prediction, label) if l != -100]\n",
    "        for prediction, label in zip(predictions, labels)\n",
    "    ]\n",
    "    return true_labels, true_predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import get_scheduler\n",
    "\n",
    "num_train_epochs = 30\n",
    "num_update_steps_per_epoch = len(train_dataloader)\n",
    "num_training_steps = num_train_epochs * num_update_steps_per_epoch\n",
    "\n",
    "lr_scheduler = get_scheduler(\n",
    "    \"linear\",\n",
    "    optimizer=optimizer,\n",
    "    num_warmup_steps=0,\n",
    "    num_training_steps=num_training_steps,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm.auto import tqdm\n",
    "import torch\n",
    "from datetime import datetime\n",
    "import os\n",
    "\n",
    "date_time = datetime.now()\n",
    "format_date = date_time.strftime('%Y-%m-%d')\n",
    "format_time = date_time.strftime('%H:%M:%S')\n",
    "\n",
    "print(f\"Date: {format_date}\")\n",
    "print(f\"Time: {format_time}\")\n",
    "\n",
    "# Replace with desire output dir\n",
    "output_dir = f\"../models/model_from_{format_date}/roberta-base_{format_time}\"\n",
    "progress_bar = tqdm(range(num_training_steps))\n",
    "\n",
    "best_f1_score = 0\n",
    "\n",
    "for epoch in range(num_train_epochs):\n",
    "    # Training\n",
    "    model.train()\n",
    "    for batch in train_dataloader:\n",
    "        outputs = model(**batch)\n",
    "        loss = outputs.loss\n",
    "        accelerator.backward(loss)\n",
    "\n",
    "        optimizer.step()\n",
    "        lr_scheduler.step()\n",
    "        optimizer.zero_grad()\n",
    "        progress_bar.update(1)\n",
    "\n",
    "    # Evaluation\n",
    "    model.eval()\n",
    "    for batch in eval_dataloader:\n",
    "        with torch.no_grad():\n",
    "            outputs = model(**batch)\n",
    "\n",
    "        predictions = outputs.logits.argmax(dim=-1)\n",
    "        labels = batch[\"labels\"]\n",
    "\n",
    "        # Necessary to pad predictions and labels for being gathered\n",
    "        predictions = accelerator.pad_across_processes(\n",
    "            predictions, dim=1, pad_index=-100)\n",
    "        labels = accelerator.pad_across_processes(\n",
    "            labels, dim=1, pad_index=-100)\n",
    "\n",
    "        predictions_gathered = accelerator.gather(predictions)\n",
    "        labels_gathered = accelerator.gather(labels)\n",
    "\n",
    "        true_predictions, true_labels = postprocess(\n",
    "            predictions_gathered, labels_gathered)\n",
    "        metric.add_batch(predictions=true_predictions, references=true_labels)\n",
    "\n",
    "    results = metric.compute()\n",
    "    print(\n",
    "        f\"epoch {epoch}:\",\n",
    "        {\n",
    "            key: results[f\"overall_{key}\"]\n",
    "            for key in [\"precision\", \"recall\", \"f1\", \"accuracy\"]\n",
    "        },\n",
    "    )\n",
    "\n",
    "    # Save and upload\n",
    "    accelerator.wait_for_everyone()\n",
    "    unwrapped_model = accelerator.unwrap_model(model)\n",
    "    if (epoch + 1) % 5 == 0:\n",
    "        output_ckpt = os.path.join(output_dir, f'epoch_{epoch + 1}')\n",
    "        print(f\"Save model at epoch {epoch + 1}\")\n",
    "        tokenizer.save_pretrained(output_ckpt)\n",
    "        unwrapped_model.save_pretrained(output_ckpt, save_function=accelerator.save)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "one_for_all",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
